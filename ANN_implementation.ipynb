{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfqa0oWnsqB9",
        "outputId": "96126e0f-d01b-4268-b430-0f5436d1d605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEmZ0nKXt8c8",
        "outputId": "3d09a3c2-63a8-4d2c-b4bf-93a0fb0b1eff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-j4L5cnWu3Jb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "DFMc_kyivL8F",
        "outputId": "b062b899-25d5-4376-f738-e16444dfa32c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ecfb015-2ead-4335-bce9-d24ffc757529\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ecfb015-2ead-4335-bce9-d24ffc757529')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ecfb015-2ead-4335-bce9-d24ffc757529 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ecfb015-2ead-4335-bce9-d24ffc757529');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=dataset.iloc[:,3:13]\n",
        "y=dataset.iloc[:,13]"
      ],
      "metadata": {
        "id": "gJeANgLNv_Az"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Feature Engineering\n",
        "geography=pd.get_dummies(x['Geography'])\n",
        "geography\n",
        "gender=pd.get_dummies(x['Gender'])\n",
        "gender"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "glPyjBLSwbt6",
        "outputId": "adab5104-08ce-4eec-c659-dfb0dbb5ee0f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Female  Male\n",
              "0          1     0\n",
              "1          1     0\n",
              "2          1     0\n",
              "3          1     0\n",
              "4          1     0\n",
              "...      ...   ...\n",
              "9995       0     1\n",
              "9996       0     1\n",
              "9997       1     0\n",
              "9998       0     1\n",
              "9999       1     0\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cf216bd-1cca-4352-b33e-375fe5172fbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cf216bd-1cca-4352-b33e-375fe5172fbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cf216bd-1cca-4352-b33e-375fe5172fbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cf216bd-1cca-4352-b33e-375fe5172fbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.drop(['Geography','Gender'],axis=1)"
      ],
      "metadata": {
        "id": "u2QAHagsxNE8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lfA_73f6xabe",
        "outputId": "76e3ed7d-3ffb-4b18-c8a4-138702a388d5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0          619   42       2       0.00              1          1   \n",
              "1          608   41       1   83807.86              1          0   \n",
              "2          502   42       8  159660.80              3          1   \n",
              "3          699   39       1       0.00              2          0   \n",
              "4          850   43       2  125510.82              1          1   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  \n",
              "0               1        101348.88  \n",
              "1               1        112542.58  \n",
              "2               0        113931.57  \n",
              "3               0         93826.63  \n",
              "4               1         79084.10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a8ef7f7-4ce6-4ec6-a3ec-5bd15dd2fd26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a8ef7f7-4ce6-4ec6-a3ec-5bd15dd2fd26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a8ef7f7-4ce6-4ec6-a3ec-5bd15dd2fd26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a8ef7f7-4ce6-4ec6-a3ec-5bd15dd2fd26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=pd.concat([x,geography,gender],axis=1)"
      ],
      "metadata": {
        "id": "bi8hlRBBxfKG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "4qdxvKRey_Y-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##feature scaling\n",
        "from sklearn.preprocessing import StandardScaler as sc\n",
        "sc=sc()"
      ],
      "metadata": {
        "id": "6yCgacGF0UwI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=sc.fit_transform(x_train)\n",
        "x_test=sc.transform(x_test)\n",
        "x_train\n",
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFOzgfum1X_p",
        "outputId": "e7104e0e-5d25-4ef2-d679-782b02a9e415"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55204276, -0.36890377,  1.04473698, ..., -0.57369368,\n",
              "         1.09168714, -1.09168714],\n",
              "       [-1.31490297,  0.10961719, -1.031415  , ..., -0.57369368,\n",
              "         1.09168714, -1.09168714],\n",
              "       [ 0.57162971,  0.30102557,  1.04473698, ...,  1.74309049,\n",
              "         1.09168714, -1.09168714],\n",
              "       ...,\n",
              "       [-0.74791227, -0.27319958, -1.37744033, ...,  1.74309049,\n",
              "        -0.91601335,  0.91601335],\n",
              "       [-0.00566991, -0.46460796, -0.33936434, ..., -0.57369368,\n",
              "        -0.91601335,  0.91601335],\n",
              "       [-0.79945688, -0.84742473,  1.04473698, ..., -0.57369368,\n",
              "        -0.91601335,  0.91601335]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjHIyuTL2Eg5",
        "outputId": "2b05cad7-0dca-49a2-ac39-50fdc0a72c5a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ANN creation"
      ],
      "metadata": {
        "id": "DiXTLKhx2R1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential as sq\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU,ReLU\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "Yqx-GfxQ2WBA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##initialize ANN\n",
        "\n",
        "classifier=sq()"
      ],
      "metadata": {
        "id": "YwUet2eD3tZH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add input layer with Dense\n",
        "classifier.add (Dense(units=11,activation='relu'))"
      ],
      "metadata": {
        "id": "qSl_udid5Nrx"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 1st hidden layer\n",
        "classifier.add(Dense(units=7, activation='relu'))"
      ],
      "metadata": {
        "id": "buTVZPoL53jE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units=5, activation='relu'))"
      ],
      "metadata": {
        "id": "r-jSkvi56IOQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add output layer\n",
        "classifier.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "iUEKz_3u6MQv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam',loss='binary_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "FM97yLJB6X3t"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=classifier.fit(x_train, y_train, validation_split=0.33,batch_size=1000, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJGKKIV37FS7",
        "outputId": "9ce63807-4d5e-4b8f-cc23-1f114ae181ea"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "6/6 [==============================] - 1s 34ms/step - loss: 0.3055 - accuracy: 0.8739 - val_loss: 0.3680 - val_accuracy: 0.8516\n",
            "Epoch 2/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8733 - val_loss: 0.3678 - val_accuracy: 0.8523\n",
            "Epoch 3/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3047 - accuracy: 0.8737 - val_loss: 0.3679 - val_accuracy: 0.8535\n",
            "Epoch 4/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8740 - val_loss: 0.3678 - val_accuracy: 0.8527\n",
            "Epoch 5/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3043 - accuracy: 0.8733 - val_loss: 0.3682 - val_accuracy: 0.8527\n",
            "Epoch 6/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3046 - accuracy: 0.8735 - val_loss: 0.3684 - val_accuracy: 0.8519\n",
            "Epoch 7/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3043 - accuracy: 0.8746 - val_loss: 0.3683 - val_accuracy: 0.8512\n",
            "Epoch 8/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3044 - accuracy: 0.8729 - val_loss: 0.3682 - val_accuracy: 0.8516\n",
            "Epoch 9/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.8740 - val_loss: 0.3683 - val_accuracy: 0.8519\n",
            "Epoch 10/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3044 - accuracy: 0.8737 - val_loss: 0.3684 - val_accuracy: 0.8519\n",
            "Epoch 11/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3044 - accuracy: 0.8739 - val_loss: 0.3683 - val_accuracy: 0.8523\n",
            "Epoch 12/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.8735 - val_loss: 0.3685 - val_accuracy: 0.8519\n",
            "Epoch 13/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.8739 - val_loss: 0.3685 - val_accuracy: 0.8516\n",
            "Epoch 14/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8737 - val_loss: 0.3683 - val_accuracy: 0.8516\n",
            "Epoch 15/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3043 - accuracy: 0.8731 - val_loss: 0.3685 - val_accuracy: 0.8523\n",
            "Epoch 16/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3045 - accuracy: 0.8733 - val_loss: 0.3683 - val_accuracy: 0.8531\n",
            "Epoch 17/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3042 - accuracy: 0.8737 - val_loss: 0.3686 - val_accuracy: 0.8523\n",
            "Epoch 18/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3046 - accuracy: 0.8742 - val_loss: 0.3688 - val_accuracy: 0.8531\n",
            "Epoch 19/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.8739 - val_loss: 0.3689 - val_accuracy: 0.8519\n",
            "Epoch 20/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3045 - accuracy: 0.8742 - val_loss: 0.3686 - val_accuracy: 0.8523\n",
            "Epoch 21/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.8739 - val_loss: 0.3689 - val_accuracy: 0.8516\n",
            "Epoch 22/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8739 - val_loss: 0.3688 - val_accuracy: 0.8527\n",
            "Epoch 23/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.8744 - val_loss: 0.3690 - val_accuracy: 0.8508\n",
            "Epoch 24/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3044 - accuracy: 0.8733 - val_loss: 0.3688 - val_accuracy: 0.8527\n",
            "Epoch 25/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8739 - val_loss: 0.3688 - val_accuracy: 0.8527\n",
            "Epoch 26/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8737 - val_loss: 0.3686 - val_accuracy: 0.8519\n",
            "Epoch 27/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3042 - accuracy: 0.8740 - val_loss: 0.3686 - val_accuracy: 0.8516\n",
            "Epoch 28/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3043 - accuracy: 0.8735 - val_loss: 0.3686 - val_accuracy: 0.8519\n",
            "Epoch 29/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3044 - accuracy: 0.8737 - val_loss: 0.3688 - val_accuracy: 0.8523\n",
            "Epoch 30/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8742 - val_loss: 0.3689 - val_accuracy: 0.8516\n",
            "Epoch 31/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8737 - val_loss: 0.3691 - val_accuracy: 0.8512\n",
            "Epoch 32/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8740 - val_loss: 0.3692 - val_accuracy: 0.8519\n",
            "Epoch 33/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3045 - accuracy: 0.8752 - val_loss: 0.3693 - val_accuracy: 0.8519\n",
            "Epoch 34/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8744 - val_loss: 0.3694 - val_accuracy: 0.8512\n",
            "Epoch 35/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8735 - val_loss: 0.3693 - val_accuracy: 0.8527\n",
            "Epoch 36/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8746 - val_loss: 0.3692 - val_accuracy: 0.8519\n",
            "Epoch 37/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.3690 - val_accuracy: 0.8523\n",
            "Epoch 38/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8750 - val_loss: 0.3689 - val_accuracy: 0.8516\n",
            "Epoch 39/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.3691 - val_accuracy: 0.8519\n",
            "Epoch 40/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8746 - val_loss: 0.3692 - val_accuracy: 0.8512\n",
            "Epoch 41/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3042 - accuracy: 0.8742 - val_loss: 0.3692 - val_accuracy: 0.8516\n",
            "Epoch 42/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3042 - accuracy: 0.8740 - val_loss: 0.3693 - val_accuracy: 0.8527\n",
            "Epoch 43/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8735 - val_loss: 0.3694 - val_accuracy: 0.8516\n",
            "Epoch 44/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.3693 - val_accuracy: 0.8523\n",
            "Epoch 45/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.3691 - val_accuracy: 0.8527\n",
            "Epoch 46/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.3691 - val_accuracy: 0.8527\n",
            "Epoch 47/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8755 - val_loss: 0.3691 - val_accuracy: 0.8523\n",
            "Epoch 48/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8753 - val_loss: 0.3691 - val_accuracy: 0.8519\n",
            "Epoch 49/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3039 - accuracy: 0.8739 - val_loss: 0.3691 - val_accuracy: 0.8523\n",
            "Epoch 50/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3047 - accuracy: 0.8746 - val_loss: 0.3692 - val_accuracy: 0.8519\n",
            "Epoch 51/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.3693 - val_accuracy: 0.8512\n",
            "Epoch 52/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8750 - val_loss: 0.3690 - val_accuracy: 0.8512\n",
            "Epoch 53/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8748 - val_loss: 0.3691 - val_accuracy: 0.8523\n",
            "Epoch 54/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8746 - val_loss: 0.3690 - val_accuracy: 0.8527\n",
            "Epoch 55/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8748 - val_loss: 0.3689 - val_accuracy: 0.8527\n",
            "Epoch 56/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.3689 - val_accuracy: 0.8531\n",
            "Epoch 57/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.3689 - val_accuracy: 0.8519\n",
            "Epoch 58/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3042 - accuracy: 0.8740 - val_loss: 0.3690 - val_accuracy: 0.8516\n",
            "Epoch 59/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8748 - val_loss: 0.3690 - val_accuracy: 0.8527\n",
            "Epoch 60/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8753 - val_loss: 0.3692 - val_accuracy: 0.8527\n",
            "Epoch 61/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3042 - accuracy: 0.8748 - val_loss: 0.3691 - val_accuracy: 0.8523\n",
            "Epoch 62/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.3690 - val_accuracy: 0.8535\n",
            "Epoch 63/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8746 - val_loss: 0.3689 - val_accuracy: 0.8531\n",
            "Epoch 64/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8750 - val_loss: 0.3690 - val_accuracy: 0.8523\n",
            "Epoch 65/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8746 - val_loss: 0.3692 - val_accuracy: 0.8527\n",
            "Epoch 66/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3040 - accuracy: 0.8746 - val_loss: 0.3692 - val_accuracy: 0.8523\n",
            "Epoch 67/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8742 - val_loss: 0.3693 - val_accuracy: 0.8523\n",
            "Epoch 68/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.8748 - val_loss: 0.3694 - val_accuracy: 0.8519\n",
            "Epoch 69/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8742 - val_loss: 0.3691 - val_accuracy: 0.8523\n",
            "Epoch 70/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.3690 - val_accuracy: 0.8519\n",
            "Epoch 71/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8752 - val_loss: 0.3689 - val_accuracy: 0.8512\n",
            "Epoch 72/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8746 - val_loss: 0.3691 - val_accuracy: 0.8519\n",
            "Epoch 73/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8746 - val_loss: 0.3691 - val_accuracy: 0.8523\n",
            "Epoch 74/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8740 - val_loss: 0.3692 - val_accuracy: 0.8535\n",
            "Epoch 75/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.3692 - val_accuracy: 0.8516\n",
            "Epoch 76/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8750 - val_loss: 0.3694 - val_accuracy: 0.8535\n",
            "Epoch 77/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8742 - val_loss: 0.3693 - val_accuracy: 0.8531\n",
            "Epoch 78/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8748 - val_loss: 0.3691 - val_accuracy: 0.8535\n",
            "Epoch 79/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8748 - val_loss: 0.3689 - val_accuracy: 0.8527\n",
            "Epoch 80/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.8746 - val_loss: 0.3688 - val_accuracy: 0.8523\n",
            "Epoch 81/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.3689 - val_accuracy: 0.8531\n",
            "Epoch 82/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8739 - val_loss: 0.3691 - val_accuracy: 0.8531\n",
            "Epoch 83/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8746 - val_loss: 0.3690 - val_accuracy: 0.8523\n",
            "Epoch 84/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.3693 - val_accuracy: 0.8523\n",
            "Epoch 85/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3041 - accuracy: 0.8744 - val_loss: 0.3693 - val_accuracy: 0.8523\n",
            "Epoch 86/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3038 - accuracy: 0.8744 - val_loss: 0.3695 - val_accuracy: 0.8516\n",
            "Epoch 87/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3045 - accuracy: 0.8746 - val_loss: 0.3695 - val_accuracy: 0.8512\n",
            "Epoch 88/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3040 - accuracy: 0.8744 - val_loss: 0.3692 - val_accuracy: 0.8519\n",
            "Epoch 89/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8737 - val_loss: 0.3692 - val_accuracy: 0.8519\n",
            "Epoch 90/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3039 - accuracy: 0.8746 - val_loss: 0.3695 - val_accuracy: 0.8527\n",
            "Epoch 91/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8746 - val_loss: 0.3697 - val_accuracy: 0.8516\n",
            "Epoch 92/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8750 - val_loss: 0.3696 - val_accuracy: 0.8527\n",
            "Epoch 93/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8744 - val_loss: 0.3697 - val_accuracy: 0.8523\n",
            "Epoch 94/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8748 - val_loss: 0.3697 - val_accuracy: 0.8512\n",
            "Epoch 95/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8753 - val_loss: 0.3698 - val_accuracy: 0.8512\n",
            "Epoch 96/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8757 - val_loss: 0.3696 - val_accuracy: 0.8512\n",
            "Epoch 97/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.8752 - val_loss: 0.3695 - val_accuracy: 0.8516\n",
            "Epoch 98/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.8748 - val_loss: 0.3695 - val_accuracy: 0.8508\n",
            "Epoch 99/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8748 - val_loss: 0.3694 - val_accuracy: 0.8512\n",
            "Epoch 100/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8746 - val_loss: 0.3693 - val_accuracy: 0.8512\n",
            "Epoch 101/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3039 - accuracy: 0.8744 - val_loss: 0.3693 - val_accuracy: 0.8512\n",
            "Epoch 102/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8740 - val_loss: 0.3693 - val_accuracy: 0.8504\n",
            "Epoch 103/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.8753 - val_loss: 0.3693 - val_accuracy: 0.8523\n",
            "Epoch 104/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8750 - val_loss: 0.3692 - val_accuracy: 0.8516\n",
            "Epoch 105/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.8750 - val_loss: 0.3693 - val_accuracy: 0.8519\n",
            "Epoch 106/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3039 - accuracy: 0.8744 - val_loss: 0.3693 - val_accuracy: 0.8512\n",
            "Epoch 107/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8737 - val_loss: 0.3691 - val_accuracy: 0.8527\n",
            "Epoch 108/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8744 - val_loss: 0.3689 - val_accuracy: 0.8512\n",
            "Epoch 109/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3039 - accuracy: 0.8748 - val_loss: 0.3687 - val_accuracy: 0.8516\n",
            "Epoch 110/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - accuracy: 0.8750 - val_loss: 0.3686 - val_accuracy: 0.8508\n",
            "Epoch 111/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8753 - val_loss: 0.3686 - val_accuracy: 0.8527\n",
            "Epoch 112/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8752 - val_loss: 0.3687 - val_accuracy: 0.8512\n",
            "Epoch 113/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8742 - val_loss: 0.3688 - val_accuracy: 0.8519\n",
            "Epoch 114/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8752 - val_loss: 0.3691 - val_accuracy: 0.8523\n",
            "Epoch 115/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8753 - val_loss: 0.3691 - val_accuracy: 0.8535\n",
            "Epoch 116/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8757 - val_loss: 0.3694 - val_accuracy: 0.8527\n",
            "Epoch 117/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8757 - val_loss: 0.3697 - val_accuracy: 0.8535\n",
            "Epoch 118/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8753 - val_loss: 0.3700 - val_accuracy: 0.8531\n",
            "Epoch 119/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3037 - accuracy: 0.8750 - val_loss: 0.3700 - val_accuracy: 0.8523\n",
            "Epoch 120/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8752 - val_loss: 0.3702 - val_accuracy: 0.8527\n",
            "Epoch 121/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8750 - val_loss: 0.3701 - val_accuracy: 0.8527\n",
            "Epoch 122/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8746 - val_loss: 0.3700 - val_accuracy: 0.8523\n",
            "Epoch 123/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3037 - accuracy: 0.8752 - val_loss: 0.3698 - val_accuracy: 0.8519\n",
            "Epoch 124/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3037 - accuracy: 0.8753 - val_loss: 0.3696 - val_accuracy: 0.8519\n",
            "Epoch 125/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8755 - val_loss: 0.3694 - val_accuracy: 0.8519\n",
            "Epoch 126/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8744 - val_loss: 0.3693 - val_accuracy: 0.8523\n",
            "Epoch 127/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8744 - val_loss: 0.3694 - val_accuracy: 0.8516\n",
            "Epoch 128/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8755 - val_loss: 0.3696 - val_accuracy: 0.8527\n",
            "Epoch 129/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8744 - val_loss: 0.3696 - val_accuracy: 0.8527\n",
            "Epoch 130/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8752 - val_loss: 0.3697 - val_accuracy: 0.8527\n",
            "Epoch 131/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8757 - val_loss: 0.3697 - val_accuracy: 0.8519\n",
            "Epoch 132/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.8757 - val_loss: 0.3696 - val_accuracy: 0.8501\n",
            "Epoch 133/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8750 - val_loss: 0.3695 - val_accuracy: 0.8531\n",
            "Epoch 134/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8755 - val_loss: 0.3693 - val_accuracy: 0.8512\n",
            "Epoch 135/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8759 - val_loss: 0.3696 - val_accuracy: 0.8516\n",
            "Epoch 136/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3037 - accuracy: 0.8753 - val_loss: 0.3696 - val_accuracy: 0.8527\n",
            "Epoch 137/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8753 - val_loss: 0.3699 - val_accuracy: 0.8519\n",
            "Epoch 138/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8755 - val_loss: 0.3698 - val_accuracy: 0.8538\n",
            "Epoch 139/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8753 - val_loss: 0.3697 - val_accuracy: 0.8538\n",
            "Epoch 140/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.8755 - val_loss: 0.3697 - val_accuracy: 0.8531\n",
            "Epoch 141/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3035 - accuracy: 0.8753 - val_loss: 0.3697 - val_accuracy: 0.8535\n",
            "Epoch 142/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8763 - val_loss: 0.3697 - val_accuracy: 0.8531\n",
            "Epoch 143/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.8759 - val_loss: 0.3698 - val_accuracy: 0.8527\n",
            "Epoch 144/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8748 - val_loss: 0.3698 - val_accuracy: 0.8523\n",
            "Epoch 145/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.8752 - val_loss: 0.3700 - val_accuracy: 0.8535\n",
            "Epoch 146/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8750 - val_loss: 0.3700 - val_accuracy: 0.8531\n",
            "Epoch 147/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8753 - val_loss: 0.3702 - val_accuracy: 0.8519\n",
            "Epoch 148/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8761 - val_loss: 0.3700 - val_accuracy: 0.8527\n",
            "Epoch 149/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.8757 - val_loss: 0.3699 - val_accuracy: 0.8519\n",
            "Epoch 150/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3037 - accuracy: 0.8757 - val_loss: 0.3702 - val_accuracy: 0.8538\n",
            "Epoch 151/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8755 - val_loss: 0.3698 - val_accuracy: 0.8523\n",
            "Epoch 152/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8757 - val_loss: 0.3697 - val_accuracy: 0.8531\n",
            "Epoch 153/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8765 - val_loss: 0.3696 - val_accuracy: 0.8531\n",
            "Epoch 154/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8757 - val_loss: 0.3694 - val_accuracy: 0.8523\n",
            "Epoch 155/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3038 - accuracy: 0.8755 - val_loss: 0.3694 - val_accuracy: 0.8538\n",
            "Epoch 156/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3036 - accuracy: 0.8744 - val_loss: 0.3694 - val_accuracy: 0.8516\n",
            "Epoch 157/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8744 - val_loss: 0.3692 - val_accuracy: 0.8523\n",
            "Epoch 158/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8744 - val_loss: 0.3694 - val_accuracy: 0.8535\n",
            "Epoch 159/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.8752 - val_loss: 0.3700 - val_accuracy: 0.8538\n",
            "Epoch 160/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.8750 - val_loss: 0.3699 - val_accuracy: 0.8531\n",
            "Epoch 161/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.8755 - val_loss: 0.3701 - val_accuracy: 0.8527\n",
            "Epoch 162/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8755 - val_loss: 0.3700 - val_accuracy: 0.8531\n",
            "Epoch 163/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.8752 - val_loss: 0.3701 - val_accuracy: 0.8535\n",
            "Epoch 164/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8752 - val_loss: 0.3700 - val_accuracy: 0.8535\n",
            "Epoch 165/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3033 - accuracy: 0.8752 - val_loss: 0.3701 - val_accuracy: 0.8527\n",
            "Epoch 166/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8757 - val_loss: 0.3702 - val_accuracy: 0.8523\n",
            "Epoch 167/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3036 - accuracy: 0.8755 - val_loss: 0.3700 - val_accuracy: 0.8535\n",
            "Epoch 168/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.8740 - val_loss: 0.3701 - val_accuracy: 0.8531\n",
            "Epoch 169/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8750 - val_loss: 0.3701 - val_accuracy: 0.8523\n",
            "Epoch 170/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8755 - val_loss: 0.3702 - val_accuracy: 0.8516\n",
            "Epoch 171/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8753 - val_loss: 0.3702 - val_accuracy: 0.8504\n",
            "Epoch 172/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8757 - val_loss: 0.3699 - val_accuracy: 0.8531\n",
            "Epoch 173/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3034 - accuracy: 0.8748 - val_loss: 0.3698 - val_accuracy: 0.8535\n",
            "Epoch 174/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8755 - val_loss: 0.3700 - val_accuracy: 0.8516\n",
            "Epoch 175/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8748 - val_loss: 0.3700 - val_accuracy: 0.8516\n",
            "Epoch 176/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3034 - accuracy: 0.8750 - val_loss: 0.3701 - val_accuracy: 0.8508\n",
            "Epoch 177/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8752 - val_loss: 0.3701 - val_accuracy: 0.8508\n",
            "Epoch 178/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8753 - val_loss: 0.3696 - val_accuracy: 0.8527\n",
            "Epoch 179/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3035 - accuracy: 0.8744 - val_loss: 0.3697 - val_accuracy: 0.8523\n",
            "Epoch 180/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8746 - val_loss: 0.3696 - val_accuracy: 0.8519\n",
            "Epoch 181/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3034 - accuracy: 0.8759 - val_loss: 0.3697 - val_accuracy: 0.8512\n",
            "Epoch 182/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3034 - accuracy: 0.8755 - val_loss: 0.3700 - val_accuracy: 0.8512\n",
            "Epoch 183/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3034 - accuracy: 0.8753 - val_loss: 0.3701 - val_accuracy: 0.8519\n",
            "Epoch 184/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3033 - accuracy: 0.8742 - val_loss: 0.3701 - val_accuracy: 0.8523\n",
            "Epoch 185/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8746 - val_loss: 0.3700 - val_accuracy: 0.8523\n",
            "Epoch 186/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3033 - accuracy: 0.8740 - val_loss: 0.3699 - val_accuracy: 0.8508\n",
            "Epoch 187/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3032 - accuracy: 0.8755 - val_loss: 0.3701 - val_accuracy: 0.8523\n",
            "Epoch 188/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3034 - accuracy: 0.8761 - val_loss: 0.3700 - val_accuracy: 0.8519\n",
            "Epoch 189/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3033 - accuracy: 0.8755 - val_loss: 0.3701 - val_accuracy: 0.8523\n",
            "Epoch 190/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3032 - accuracy: 0.8755 - val_loss: 0.3702 - val_accuracy: 0.8519\n",
            "Epoch 191/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3033 - accuracy: 0.8744 - val_loss: 0.3702 - val_accuracy: 0.8527\n",
            "Epoch 192/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8739 - val_loss: 0.3703 - val_accuracy: 0.8531\n",
            "Epoch 193/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3033 - accuracy: 0.8742 - val_loss: 0.3703 - val_accuracy: 0.8527\n",
            "Epoch 194/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3032 - accuracy: 0.8737 - val_loss: 0.3702 - val_accuracy: 0.8527\n",
            "Epoch 195/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3033 - accuracy: 0.8744 - val_loss: 0.3702 - val_accuracy: 0.8531\n",
            "Epoch 196/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8742 - val_loss: 0.3702 - val_accuracy: 0.8527\n",
            "Epoch 197/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3036 - accuracy: 0.8748 - val_loss: 0.3703 - val_accuracy: 0.8512\n",
            "Epoch 198/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.8752 - val_loss: 0.3702 - val_accuracy: 0.8519\n",
            "Epoch 199/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8753 - val_loss: 0.3702 - val_accuracy: 0.8516\n",
            "Epoch 200/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3033 - accuracy: 0.8744 - val_loss: 0.3701 - val_accuracy: 0.8523\n",
            "Epoch 201/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3033 - accuracy: 0.8740 - val_loss: 0.3700 - val_accuracy: 0.8516\n",
            "Epoch 202/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3033 - accuracy: 0.8740 - val_loss: 0.3699 - val_accuracy: 0.8519\n",
            "Epoch 203/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3033 - accuracy: 0.8759 - val_loss: 0.3700 - val_accuracy: 0.8516\n",
            "Epoch 204/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3032 - accuracy: 0.8757 - val_loss: 0.3704 - val_accuracy: 0.8519\n",
            "Epoch 205/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3032 - accuracy: 0.8757 - val_loss: 0.3706 - val_accuracy: 0.8516\n",
            "Epoch 206/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8748 - val_loss: 0.3706 - val_accuracy: 0.8516\n",
            "Epoch 207/1000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3031 - accuracy: 0.8753 - val_loss: 0.3706 - val_accuracy: 0.8516\n",
            "Epoch 208/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3031 - accuracy: 0.8755 - val_loss: 0.3704 - val_accuracy: 0.8516\n",
            "Epoch 209/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3033 - accuracy: 0.8759 - val_loss: 0.3703 - val_accuracy: 0.8523\n",
            "Epoch 210/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3032 - accuracy: 0.8763 - val_loss: 0.3705 - val_accuracy: 0.8523\n",
            "Epoch 211/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3032 - accuracy: 0.8763 - val_loss: 0.3703 - val_accuracy: 0.8523\n",
            "Epoch 212/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3031 - accuracy: 0.8765 - val_loss: 0.3703 - val_accuracy: 0.8523\n",
            "Epoch 213/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8753 - val_loss: 0.3701 - val_accuracy: 0.8523\n",
            "Epoch 214/1000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3032 - accuracy: 0.8755 - val_loss: 0.3701 - val_accuracy: 0.8519\n",
            "Epoch 215/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3034 - accuracy: 0.8746 - val_loss: 0.3702 - val_accuracy: 0.8523\n",
            "Epoch 216/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3034 - accuracy: 0.8746 - val_loss: 0.3702 - val_accuracy: 0.8508\n",
            "Epoch 217/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3033 - accuracy: 0.8748 - val_loss: 0.3700 - val_accuracy: 0.8508\n",
            "Epoch 218/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8753 - val_loss: 0.3700 - val_accuracy: 0.8523\n",
            "Epoch 219/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8744 - val_loss: 0.3701 - val_accuracy: 0.8516\n",
            "Epoch 220/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3031 - accuracy: 0.8742 - val_loss: 0.3704 - val_accuracy: 0.8516\n",
            "Epoch 221/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3032 - accuracy: 0.8753 - val_loss: 0.3707 - val_accuracy: 0.8519\n",
            "Epoch 222/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3031 - accuracy: 0.8750 - val_loss: 0.3708 - val_accuracy: 0.8512\n",
            "Epoch 223/1000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3033 - accuracy: 0.8750 - val_loss: 0.3710 - val_accuracy: 0.8516\n",
            "Epoch 224/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3032 - accuracy: 0.8750 - val_loss: 0.3707 - val_accuracy: 0.8512\n",
            "Epoch 225/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3031 - accuracy: 0.8753 - val_loss: 0.3706 - val_accuracy: 0.8519\n",
            "Epoch 226/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3033 - accuracy: 0.8753 - val_loss: 0.3707 - val_accuracy: 0.8531\n",
            "Epoch 227/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3030 - accuracy: 0.8759 - val_loss: 0.3708 - val_accuracy: 0.8527\n",
            "Epoch 228/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3033 - accuracy: 0.8750 - val_loss: 0.3712 - val_accuracy: 0.8535\n",
            "Epoch 229/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3031 - accuracy: 0.8748 - val_loss: 0.3708 - val_accuracy: 0.8508\n",
            "Epoch 230/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.8748 - val_loss: 0.3709 - val_accuracy: 0.8516\n",
            "Epoch 231/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3033 - accuracy: 0.8744 - val_loss: 0.3704 - val_accuracy: 0.8519\n",
            "Epoch 232/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.8750 - val_loss: 0.3702 - val_accuracy: 0.8519\n",
            "Epoch 233/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3031 - accuracy: 0.8746 - val_loss: 0.3703 - val_accuracy: 0.8523\n",
            "Epoch 234/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3030 - accuracy: 0.8755 - val_loss: 0.3703 - val_accuracy: 0.8519\n",
            "Epoch 235/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3031 - accuracy: 0.8761 - val_loss: 0.3703 - val_accuracy: 0.8523\n",
            "Epoch 236/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3031 - accuracy: 0.8768 - val_loss: 0.3706 - val_accuracy: 0.8516\n",
            "Epoch 237/1000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3033 - accuracy: 0.8755 - val_loss: 0.3708 - val_accuracy: 0.8519\n",
            "Epoch 238/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3030 - accuracy: 0.8752 - val_loss: 0.3707 - val_accuracy: 0.8519\n",
            "Epoch 239/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.8748 - val_loss: 0.3705 - val_accuracy: 0.8527\n",
            "Epoch 240/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3030 - accuracy: 0.8753 - val_loss: 0.3704 - val_accuracy: 0.8519\n",
            "Epoch 241/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3032 - accuracy: 0.8742 - val_loss: 0.3707 - val_accuracy: 0.8531\n",
            "Epoch 242/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3031 - accuracy: 0.8748 - val_loss: 0.3708 - val_accuracy: 0.8535\n",
            "Epoch 243/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3030 - accuracy: 0.8755 - val_loss: 0.3709 - val_accuracy: 0.8542\n",
            "Epoch 244/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3030 - accuracy: 0.8750 - val_loss: 0.3709 - val_accuracy: 0.8535\n",
            "Epoch 245/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3031 - accuracy: 0.8748 - val_loss: 0.3710 - val_accuracy: 0.8535\n",
            "Epoch 246/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3030 - accuracy: 0.8748 - val_loss: 0.3710 - val_accuracy: 0.8527\n",
            "Epoch 247/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3030 - accuracy: 0.8746 - val_loss: 0.3711 - val_accuracy: 0.8519\n",
            "Epoch 248/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3030 - accuracy: 0.8759 - val_loss: 0.3709 - val_accuracy: 0.8527\n",
            "Epoch 249/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3030 - accuracy: 0.8759 - val_loss: 0.3710 - val_accuracy: 0.8527\n",
            "Epoch 250/1000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3030 - accuracy: 0.8763 - val_loss: 0.3711 - val_accuracy: 0.8527\n",
            "Epoch 251/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3029 - accuracy: 0.8748 - val_loss: 0.3711 - val_accuracy: 0.8512\n",
            "Epoch 252/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3032 - accuracy: 0.8740 - val_loss: 0.3712 - val_accuracy: 0.8512\n",
            "Epoch 253/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3030 - accuracy: 0.8752 - val_loss: 0.3710 - val_accuracy: 0.8519\n",
            "Epoch 254/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3030 - accuracy: 0.8748 - val_loss: 0.3709 - val_accuracy: 0.8516\n",
            "Epoch 255/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3029 - accuracy: 0.8750 - val_loss: 0.3707 - val_accuracy: 0.8519\n",
            "Epoch 256/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3030 - accuracy: 0.8746 - val_loss: 0.3707 - val_accuracy: 0.8542\n",
            "Epoch 257/1000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3029 - accuracy: 0.8748 - val_loss: 0.3705 - val_accuracy: 0.8527\n",
            "Epoch 258/1000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3029 - accuracy: 0.8753 - val_loss: 0.3705 - val_accuracy: 0.8527\n",
            "Epoch 259/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3031 - accuracy: 0.8750 - val_loss: 0.3706 - val_accuracy: 0.8519\n",
            "Epoch 260/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3028 - accuracy: 0.8744 - val_loss: 0.3707 - val_accuracy: 0.8531\n",
            "Epoch 261/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3027 - accuracy: 0.8752 - val_loss: 0.3708 - val_accuracy: 0.8535\n",
            "Epoch 262/1000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3028 - accuracy: 0.8746 - val_loss: 0.3710 - val_accuracy: 0.8531\n",
            "Epoch 263/1000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3028 - accuracy: 0.8748 - val_loss: 0.3710 - val_accuracy: 0.8531\n",
            "Epoch 264/1000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.3028 - accuracy: 0.8753 - val_loss: 0.3712 - val_accuracy: 0.8523\n",
            "Epoch 265/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3027 - accuracy: 0.8755 - val_loss: 0.3713 - val_accuracy: 0.8527\n",
            "Epoch 266/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3028 - accuracy: 0.8759 - val_loss: 0.3714 - val_accuracy: 0.8527\n",
            "Epoch 267/1000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3028 - accuracy: 0.8757 - val_loss: 0.3713 - val_accuracy: 0.8519\n",
            "Epoch 268/1000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3029 - accuracy: 0.8750 - val_loss: 0.3715 - val_accuracy: 0.8519\n",
            "Epoch 269/1000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3027 - accuracy: 0.8750 - val_loss: 0.3714 - val_accuracy: 0.8523\n",
            "Epoch 270/1000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3029 - accuracy: 0.8750 - val_loss: 0.3713 - val_accuracy: 0.8531\n",
            "Epoch 271/1000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.3030 - accuracy: 0.8748 - val_loss: 0.3714 - val_accuracy: 0.8523\n",
            "Epoch 272/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3028 - accuracy: 0.8744 - val_loss: 0.3712 - val_accuracy: 0.8531\n",
            "Epoch 273/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3029 - accuracy: 0.8750 - val_loss: 0.3712 - val_accuracy: 0.8527\n",
            "Epoch 274/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3030 - accuracy: 0.8759 - val_loss: 0.3710 - val_accuracy: 0.8519\n",
            "Epoch 275/1000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3028 - accuracy: 0.8752 - val_loss: 0.3709 - val_accuracy: 0.8523\n",
            "Epoch 276/1000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3029 - accuracy: 0.8752 - val_loss: 0.3708 - val_accuracy: 0.8527\n",
            "Epoch 277/1000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3028 - accuracy: 0.8748 - val_loss: 0.3707 - val_accuracy: 0.8523\n",
            "Epoch 278/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3027 - accuracy: 0.8746 - val_loss: 0.3711 - val_accuracy: 0.8516\n",
            "Epoch 279/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3028 - accuracy: 0.8744 - val_loss: 0.3711 - val_accuracy: 0.8531\n",
            "Epoch 280/1000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3026 - accuracy: 0.8746 - val_loss: 0.3711 - val_accuracy: 0.8523\n",
            "Epoch 281/1000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3027 - accuracy: 0.8748 - val_loss: 0.3711 - val_accuracy: 0.8527\n",
            "Epoch 282/1000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3028 - accuracy: 0.8746 - val_loss: 0.3713 - val_accuracy: 0.8523\n",
            "Epoch 283/1000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3028 - accuracy: 0.8753 - val_loss: 0.3713 - val_accuracy: 0.8504\n",
            "Epoch 284/1000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3026 - accuracy: 0.8752 - val_loss: 0.3714 - val_accuracy: 0.8535\n",
            "Epoch 285/1000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.3028 - accuracy: 0.8757 - val_loss: 0.3716 - val_accuracy: 0.8535\n",
            "Epoch 286/1000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3028 - accuracy: 0.8746 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 287/1000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3028 - accuracy: 0.8744 - val_loss: 0.3711 - val_accuracy: 0.8535\n",
            "Epoch 288/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3026 - accuracy: 0.8742 - val_loss: 0.3710 - val_accuracy: 0.8535\n",
            "Epoch 289/1000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3027 - accuracy: 0.8750 - val_loss: 0.3712 - val_accuracy: 0.8523\n",
            "Epoch 290/1000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.3027 - accuracy: 0.8744 - val_loss: 0.3711 - val_accuracy: 0.8527\n",
            "Epoch 291/1000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.3027 - accuracy: 0.8744 - val_loss: 0.3710 - val_accuracy: 0.8523\n",
            "Epoch 292/1000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3026 - accuracy: 0.8750 - val_loss: 0.3709 - val_accuracy: 0.8527\n",
            "Epoch 293/1000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3027 - accuracy: 0.8744 - val_loss: 0.3709 - val_accuracy: 0.8531\n",
            "Epoch 294/1000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3026 - accuracy: 0.8753 - val_loss: 0.3710 - val_accuracy: 0.8519\n",
            "Epoch 295/1000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.3025 - accuracy: 0.8752 - val_loss: 0.3711 - val_accuracy: 0.8527\n",
            "Epoch 296/1000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3026 - accuracy: 0.8752 - val_loss: 0.3710 - val_accuracy: 0.8516\n",
            "Epoch 297/1000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.3026 - accuracy: 0.8744 - val_loss: 0.3707 - val_accuracy: 0.8523\n",
            "Epoch 298/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3028 - accuracy: 0.8752 - val_loss: 0.3706 - val_accuracy: 0.8519\n",
            "Epoch 299/1000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.3027 - accuracy: 0.8752 - val_loss: 0.3710 - val_accuracy: 0.8516\n",
            "Epoch 300/1000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3027 - accuracy: 0.8746 - val_loss: 0.3710 - val_accuracy: 0.8512\n",
            "Epoch 301/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3028 - accuracy: 0.8740 - val_loss: 0.3713 - val_accuracy: 0.8516\n",
            "Epoch 302/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.8744 - val_loss: 0.3714 - val_accuracy: 0.8512\n",
            "Epoch 303/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.8750 - val_loss: 0.3714 - val_accuracy: 0.8519\n",
            "Epoch 304/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8746 - val_loss: 0.3713 - val_accuracy: 0.8535\n",
            "Epoch 305/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8740 - val_loss: 0.3712 - val_accuracy: 0.8538\n",
            "Epoch 306/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3026 - accuracy: 0.8748 - val_loss: 0.3714 - val_accuracy: 0.8535\n",
            "Epoch 307/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3026 - accuracy: 0.8748 - val_loss: 0.3715 - val_accuracy: 0.8523\n",
            "Epoch 308/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 0.8746 - val_loss: 0.3713 - val_accuracy: 0.8531\n",
            "Epoch 309/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.8740 - val_loss: 0.3712 - val_accuracy: 0.8535\n",
            "Epoch 310/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3028 - accuracy: 0.8755 - val_loss: 0.3708 - val_accuracy: 0.8535\n",
            "Epoch 311/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8752 - val_loss: 0.3708 - val_accuracy: 0.8527\n",
            "Epoch 312/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8742 - val_loss: 0.3707 - val_accuracy: 0.8523\n",
            "Epoch 313/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3025 - accuracy: 0.8744 - val_loss: 0.3710 - val_accuracy: 0.8535\n",
            "Epoch 314/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3028 - accuracy: 0.8763 - val_loss: 0.3711 - val_accuracy: 0.8516\n",
            "Epoch 315/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3026 - accuracy: 0.8759 - val_loss: 0.3712 - val_accuracy: 0.8519\n",
            "Epoch 316/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3026 - accuracy: 0.8750 - val_loss: 0.3713 - val_accuracy: 0.8519\n",
            "Epoch 317/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8759 - val_loss: 0.3712 - val_accuracy: 0.8519\n",
            "Epoch 318/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8752 - val_loss: 0.3713 - val_accuracy: 0.8519\n",
            "Epoch 319/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3025 - accuracy: 0.8752 - val_loss: 0.3713 - val_accuracy: 0.8519\n",
            "Epoch 320/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8746 - val_loss: 0.3714 - val_accuracy: 0.8516\n",
            "Epoch 321/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8744 - val_loss: 0.3713 - val_accuracy: 0.8519\n",
            "Epoch 322/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8748 - val_loss: 0.3712 - val_accuracy: 0.8516\n",
            "Epoch 323/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 0.8748 - val_loss: 0.3711 - val_accuracy: 0.8519\n",
            "Epoch 324/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8746 - val_loss: 0.3712 - val_accuracy: 0.8519\n",
            "Epoch 325/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8748 - val_loss: 0.3710 - val_accuracy: 0.8516\n",
            "Epoch 326/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3024 - accuracy: 0.8750 - val_loss: 0.3713 - val_accuracy: 0.8538\n",
            "Epoch 327/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3024 - accuracy: 0.8746 - val_loss: 0.3715 - val_accuracy: 0.8542\n",
            "Epoch 328/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3025 - accuracy: 0.8752 - val_loss: 0.3718 - val_accuracy: 0.8519\n",
            "Epoch 329/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8748 - val_loss: 0.3719 - val_accuracy: 0.8516\n",
            "Epoch 330/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8753 - val_loss: 0.3719 - val_accuracy: 0.8527\n",
            "Epoch 331/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.8746 - val_loss: 0.3720 - val_accuracy: 0.8512\n",
            "Epoch 332/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8737 - val_loss: 0.3717 - val_accuracy: 0.8535\n",
            "Epoch 333/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3026 - accuracy: 0.8755 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 334/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8763 - val_loss: 0.3718 - val_accuracy: 0.8523\n",
            "Epoch 335/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3026 - accuracy: 0.8752 - val_loss: 0.3715 - val_accuracy: 0.8527\n",
            "Epoch 336/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3026 - accuracy: 0.8753 - val_loss: 0.3714 - val_accuracy: 0.8519\n",
            "Epoch 337/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3026 - accuracy: 0.8759 - val_loss: 0.3716 - val_accuracy: 0.8508\n",
            "Epoch 338/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8761 - val_loss: 0.3716 - val_accuracy: 0.8512\n",
            "Epoch 339/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3025 - accuracy: 0.8750 - val_loss: 0.3720 - val_accuracy: 0.8523\n",
            "Epoch 340/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.8761 - val_loss: 0.3714 - val_accuracy: 0.8519\n",
            "Epoch 341/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.8759 - val_loss: 0.3713 - val_accuracy: 0.8508\n",
            "Epoch 342/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8759 - val_loss: 0.3712 - val_accuracy: 0.8531\n",
            "Epoch 343/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8753 - val_loss: 0.3712 - val_accuracy: 0.8527\n",
            "Epoch 344/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.8752 - val_loss: 0.3711 - val_accuracy: 0.8512\n",
            "Epoch 345/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3026 - accuracy: 0.8748 - val_loss: 0.3714 - val_accuracy: 0.8523\n",
            "Epoch 346/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8752 - val_loss: 0.3709 - val_accuracy: 0.8523\n",
            "Epoch 347/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3024 - accuracy: 0.8748 - val_loss: 0.3715 - val_accuracy: 0.8504\n",
            "Epoch 348/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8753 - val_loss: 0.3713 - val_accuracy: 0.8523\n",
            "Epoch 349/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3026 - accuracy: 0.8755 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 350/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3025 - accuracy: 0.8761 - val_loss: 0.3714 - val_accuracy: 0.8527\n",
            "Epoch 351/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8753 - val_loss: 0.3712 - val_accuracy: 0.8508\n",
            "Epoch 352/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8753 - val_loss: 0.3712 - val_accuracy: 0.8516\n",
            "Epoch 353/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.8752 - val_loss: 0.3710 - val_accuracy: 0.8527\n",
            "Epoch 354/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.8750 - val_loss: 0.3710 - val_accuracy: 0.8523\n",
            "Epoch 355/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3025 - accuracy: 0.8739 - val_loss: 0.3710 - val_accuracy: 0.8516\n",
            "Epoch 356/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3024 - accuracy: 0.8742 - val_loss: 0.3711 - val_accuracy: 0.8516\n",
            "Epoch 357/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8740 - val_loss: 0.3710 - val_accuracy: 0.8523\n",
            "Epoch 358/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.8752 - val_loss: 0.3708 - val_accuracy: 0.8523\n",
            "Epoch 359/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8753 - val_loss: 0.3709 - val_accuracy: 0.8535\n",
            "Epoch 360/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3023 - accuracy: 0.8746 - val_loss: 0.3710 - val_accuracy: 0.8542\n",
            "Epoch 361/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3022 - accuracy: 0.8750 - val_loss: 0.3712 - val_accuracy: 0.8523\n",
            "Epoch 362/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8752 - val_loss: 0.3714 - val_accuracy: 0.8527\n",
            "Epoch 363/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3025 - accuracy: 0.8750 - val_loss: 0.3716 - val_accuracy: 0.8512\n",
            "Epoch 364/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3022 - accuracy: 0.8755 - val_loss: 0.3714 - val_accuracy: 0.8519\n",
            "Epoch 365/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3023 - accuracy: 0.8742 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 366/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3022 - accuracy: 0.8750 - val_loss: 0.3718 - val_accuracy: 0.8531\n",
            "Epoch 367/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8748 - val_loss: 0.3721 - val_accuracy: 0.8531\n",
            "Epoch 368/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8742 - val_loss: 0.3718 - val_accuracy: 0.8546\n",
            "Epoch 369/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3023 - accuracy: 0.8759 - val_loss: 0.3715 - val_accuracy: 0.8542\n",
            "Epoch 370/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8761 - val_loss: 0.3714 - val_accuracy: 0.8535\n",
            "Epoch 371/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3021 - accuracy: 0.8752 - val_loss: 0.3716 - val_accuracy: 0.8538\n",
            "Epoch 372/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3022 - accuracy: 0.8755 - val_loss: 0.3715 - val_accuracy: 0.8523\n",
            "Epoch 373/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.8765 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 374/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3026 - accuracy: 0.8757 - val_loss: 0.3714 - val_accuracy: 0.8519\n",
            "Epoch 375/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8742 - val_loss: 0.3720 - val_accuracy: 0.8497\n",
            "Epoch 376/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8755 - val_loss: 0.3714 - val_accuracy: 0.8531\n",
            "Epoch 377/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.8763 - val_loss: 0.3714 - val_accuracy: 0.8531\n",
            "Epoch 378/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8753 - val_loss: 0.3710 - val_accuracy: 0.8531\n",
            "Epoch 379/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8744 - val_loss: 0.3712 - val_accuracy: 0.8527\n",
            "Epoch 380/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3022 - accuracy: 0.8742 - val_loss: 0.3711 - val_accuracy: 0.8535\n",
            "Epoch 381/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8746 - val_loss: 0.3713 - val_accuracy: 0.8527\n",
            "Epoch 382/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3022 - accuracy: 0.8757 - val_loss: 0.3714 - val_accuracy: 0.8516\n",
            "Epoch 383/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8763 - val_loss: 0.3714 - val_accuracy: 0.8535\n",
            "Epoch 384/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3022 - accuracy: 0.8757 - val_loss: 0.3713 - val_accuracy: 0.8546\n",
            "Epoch 385/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8753 - val_loss: 0.3712 - val_accuracy: 0.8531\n",
            "Epoch 386/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8763 - val_loss: 0.3712 - val_accuracy: 0.8531\n",
            "Epoch 387/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8753 - val_loss: 0.3710 - val_accuracy: 0.8523\n",
            "Epoch 388/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3021 - accuracy: 0.8757 - val_loss: 0.3714 - val_accuracy: 0.8519\n",
            "Epoch 389/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8753 - val_loss: 0.3717 - val_accuracy: 0.8538\n",
            "Epoch 390/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8765 - val_loss: 0.3718 - val_accuracy: 0.8535\n",
            "Epoch 391/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8757 - val_loss: 0.3718 - val_accuracy: 0.8538\n",
            "Epoch 392/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8753 - val_loss: 0.3717 - val_accuracy: 0.8516\n",
            "Epoch 393/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3020 - accuracy: 0.8765 - val_loss: 0.3718 - val_accuracy: 0.8504\n",
            "Epoch 394/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8752 - val_loss: 0.3718 - val_accuracy: 0.8519\n",
            "Epoch 395/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 396/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8765 - val_loss: 0.3715 - val_accuracy: 0.8512\n",
            "Epoch 397/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8755 - val_loss: 0.3714 - val_accuracy: 0.8516\n",
            "Epoch 398/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8750 - val_loss: 0.3711 - val_accuracy: 0.8512\n",
            "Epoch 399/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8752 - val_loss: 0.3710 - val_accuracy: 0.8508\n",
            "Epoch 400/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3020 - accuracy: 0.8755 - val_loss: 0.3711 - val_accuracy: 0.8516\n",
            "Epoch 401/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8752 - val_loss: 0.3711 - val_accuracy: 0.8512\n",
            "Epoch 402/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8755 - val_loss: 0.3711 - val_accuracy: 0.8531\n",
            "Epoch 403/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8761 - val_loss: 0.3711 - val_accuracy: 0.8523\n",
            "Epoch 404/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8763 - val_loss: 0.3710 - val_accuracy: 0.8519\n",
            "Epoch 405/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8753 - val_loss: 0.3713 - val_accuracy: 0.8519\n",
            "Epoch 406/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.8763 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 407/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8757 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 408/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8763 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 409/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8768 - val_loss: 0.3718 - val_accuracy: 0.8535\n",
            "Epoch 410/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8759 - val_loss: 0.3717 - val_accuracy: 0.8538\n",
            "Epoch 411/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3021 - accuracy: 0.8763 - val_loss: 0.3719 - val_accuracy: 0.8531\n",
            "Epoch 412/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8759 - val_loss: 0.3718 - val_accuracy: 0.8523\n",
            "Epoch 413/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8757 - val_loss: 0.3718 - val_accuracy: 0.8523\n",
            "Epoch 414/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8753 - val_loss: 0.3719 - val_accuracy: 0.8531\n",
            "Epoch 415/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8755 - val_loss: 0.3721 - val_accuracy: 0.8523\n",
            "Epoch 416/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8757 - val_loss: 0.3720 - val_accuracy: 0.8519\n",
            "Epoch 417/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8759 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 418/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 419/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3020 - accuracy: 0.8755 - val_loss: 0.3717 - val_accuracy: 0.8512\n",
            "Epoch 420/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8752 - val_loss: 0.3714 - val_accuracy: 0.8512\n",
            "Epoch 421/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8755 - val_loss: 0.3714 - val_accuracy: 0.8512\n",
            "Epoch 422/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8755 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 423/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3019 - accuracy: 0.8767 - val_loss: 0.3717 - val_accuracy: 0.8523\n",
            "Epoch 424/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8761 - val_loss: 0.3717 - val_accuracy: 0.8523\n",
            "Epoch 425/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.3717 - val_accuracy: 0.8504\n",
            "Epoch 426/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.3716 - val_accuracy: 0.8504\n",
            "Epoch 427/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8753 - val_loss: 0.3715 - val_accuracy: 0.8516\n",
            "Epoch 428/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8759 - val_loss: 0.3714 - val_accuracy: 0.8523\n",
            "Epoch 429/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3020 - accuracy: 0.8755 - val_loss: 0.3715 - val_accuracy: 0.8523\n",
            "Epoch 430/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3020 - accuracy: 0.8750 - val_loss: 0.3715 - val_accuracy: 0.8508\n",
            "Epoch 431/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8759 - val_loss: 0.3712 - val_accuracy: 0.8508\n",
            "Epoch 432/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8752 - val_loss: 0.3710 - val_accuracy: 0.8527\n",
            "Epoch 433/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8759 - val_loss: 0.3711 - val_accuracy: 0.8519\n",
            "Epoch 434/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8761 - val_loss: 0.3713 - val_accuracy: 0.8523\n",
            "Epoch 435/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8755 - val_loss: 0.3714 - val_accuracy: 0.8531\n",
            "Epoch 436/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8763 - val_loss: 0.3715 - val_accuracy: 0.8527\n",
            "Epoch 437/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8767 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 438/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3018 - accuracy: 0.8759 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 439/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 440/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.8755 - val_loss: 0.3716 - val_accuracy: 0.8512\n",
            "Epoch 441/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8748 - val_loss: 0.3715 - val_accuracy: 0.8508\n",
            "Epoch 442/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8750 - val_loss: 0.3716 - val_accuracy: 0.8531\n",
            "Epoch 443/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.3715 - val_accuracy: 0.8523\n",
            "Epoch 444/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8752 - val_loss: 0.3714 - val_accuracy: 0.8527\n",
            "Epoch 445/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.8757 - val_loss: 0.3714 - val_accuracy: 0.8512\n",
            "Epoch 446/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8755 - val_loss: 0.3713 - val_accuracy: 0.8519\n",
            "Epoch 447/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3018 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 448/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8763 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 449/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8765 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 450/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8757 - val_loss: 0.3715 - val_accuracy: 0.8523\n",
            "Epoch 451/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8755 - val_loss: 0.3718 - val_accuracy: 0.8523\n",
            "Epoch 452/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8759 - val_loss: 0.3718 - val_accuracy: 0.8516\n",
            "Epoch 453/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8761 - val_loss: 0.3720 - val_accuracy: 0.8512\n",
            "Epoch 454/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8759 - val_loss: 0.3719 - val_accuracy: 0.8523\n",
            "Epoch 455/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.3719 - val_accuracy: 0.8535\n",
            "Epoch 456/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8761 - val_loss: 0.3718 - val_accuracy: 0.8538\n",
            "Epoch 457/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8770 - val_loss: 0.3718 - val_accuracy: 0.8527\n",
            "Epoch 458/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8761 - val_loss: 0.3721 - val_accuracy: 0.8519\n",
            "Epoch 459/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8765 - val_loss: 0.3718 - val_accuracy: 0.8531\n",
            "Epoch 460/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3017 - accuracy: 0.8753 - val_loss: 0.3719 - val_accuracy: 0.8527\n",
            "Epoch 461/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8759 - val_loss: 0.3722 - val_accuracy: 0.8519\n",
            "Epoch 462/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8750 - val_loss: 0.3723 - val_accuracy: 0.8523\n",
            "Epoch 463/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.3722 - val_accuracy: 0.8523\n",
            "Epoch 464/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.8750 - val_loss: 0.3720 - val_accuracy: 0.8531\n",
            "Epoch 465/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8748 - val_loss: 0.3721 - val_accuracy: 0.8523\n",
            "Epoch 466/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.8755 - val_loss: 0.3719 - val_accuracy: 0.8523\n",
            "Epoch 467/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.3717 - val_accuracy: 0.8523\n",
            "Epoch 468/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8752 - val_loss: 0.3716 - val_accuracy: 0.8531\n",
            "Epoch 469/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8752 - val_loss: 0.3715 - val_accuracy: 0.8516\n",
            "Epoch 470/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8746 - val_loss: 0.3718 - val_accuracy: 0.8508\n",
            "Epoch 471/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3020 - accuracy: 0.8759 - val_loss: 0.3721 - val_accuracy: 0.8516\n",
            "Epoch 472/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3018 - accuracy: 0.8755 - val_loss: 0.3721 - val_accuracy: 0.8519\n",
            "Epoch 473/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3016 - accuracy: 0.8753 - val_loss: 0.3722 - val_accuracy: 0.8523\n",
            "Epoch 474/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8761 - val_loss: 0.3723 - val_accuracy: 0.8527\n",
            "Epoch 475/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8755 - val_loss: 0.3723 - val_accuracy: 0.8535\n",
            "Epoch 476/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.3722 - val_accuracy: 0.8527\n",
            "Epoch 477/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8755 - val_loss: 0.3722 - val_accuracy: 0.8523\n",
            "Epoch 478/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8759 - val_loss: 0.3720 - val_accuracy: 0.8527\n",
            "Epoch 479/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8757 - val_loss: 0.3717 - val_accuracy: 0.8523\n",
            "Epoch 480/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8750 - val_loss: 0.3718 - val_accuracy: 0.8523\n",
            "Epoch 481/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8750 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 482/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8752 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 483/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.3715 - val_accuracy: 0.8519\n",
            "Epoch 484/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.3714 - val_accuracy: 0.8512\n",
            "Epoch 485/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8753 - val_loss: 0.3719 - val_accuracy: 0.8504\n",
            "Epoch 486/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8757 - val_loss: 0.3716 - val_accuracy: 0.8531\n",
            "Epoch 487/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.3716 - val_accuracy: 0.8535\n",
            "Epoch 488/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3017 - accuracy: 0.8757 - val_loss: 0.3716 - val_accuracy: 0.8527\n",
            "Epoch 489/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8752 - val_loss: 0.3717 - val_accuracy: 0.8519\n",
            "Epoch 490/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8748 - val_loss: 0.3719 - val_accuracy: 0.8519\n",
            "Epoch 491/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8752 - val_loss: 0.3720 - val_accuracy: 0.8519\n",
            "Epoch 492/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8757 - val_loss: 0.3720 - val_accuracy: 0.8527\n",
            "Epoch 493/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3018 - accuracy: 0.8759 - val_loss: 0.3718 - val_accuracy: 0.8512\n",
            "Epoch 494/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8767 - val_loss: 0.3717 - val_accuracy: 0.8512\n",
            "Epoch 495/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8765 - val_loss: 0.3717 - val_accuracy: 0.8523\n",
            "Epoch 496/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3016 - accuracy: 0.8765 - val_loss: 0.3717 - val_accuracy: 0.8535\n",
            "Epoch 497/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8765 - val_loss: 0.3717 - val_accuracy: 0.8542\n",
            "Epoch 498/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8542\n",
            "Epoch 499/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8753 - val_loss: 0.3714 - val_accuracy: 0.8535\n",
            "Epoch 500/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8750 - val_loss: 0.3714 - val_accuracy: 0.8523\n",
            "Epoch 501/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8748 - val_loss: 0.3712 - val_accuracy: 0.8527\n",
            "Epoch 502/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8750 - val_loss: 0.3712 - val_accuracy: 0.8523\n",
            "Epoch 503/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8752 - val_loss: 0.3715 - val_accuracy: 0.8527\n",
            "Epoch 504/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 505/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8748 - val_loss: 0.3716 - val_accuracy: 0.8516\n",
            "Epoch 506/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8748 - val_loss: 0.3715 - val_accuracy: 0.8512\n",
            "Epoch 507/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8508\n",
            "Epoch 508/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3017 - accuracy: 0.8753 - val_loss: 0.3715 - val_accuracy: 0.8531\n",
            "Epoch 509/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8535\n",
            "Epoch 510/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3015 - accuracy: 0.8755 - val_loss: 0.3717 - val_accuracy: 0.8527\n",
            "Epoch 511/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8750 - val_loss: 0.3718 - val_accuracy: 0.8531\n",
            "Epoch 512/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3015 - accuracy: 0.8752 - val_loss: 0.3717 - val_accuracy: 0.8531\n",
            "Epoch 513/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8752 - val_loss: 0.3717 - val_accuracy: 0.8527\n",
            "Epoch 514/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3015 - accuracy: 0.8753 - val_loss: 0.3718 - val_accuracy: 0.8535\n",
            "Epoch 515/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8761 - val_loss: 0.3717 - val_accuracy: 0.8531\n",
            "Epoch 516/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8757 - val_loss: 0.3718 - val_accuracy: 0.8516\n",
            "Epoch 517/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8763 - val_loss: 0.3720 - val_accuracy: 0.8523\n",
            "Epoch 518/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8759 - val_loss: 0.3720 - val_accuracy: 0.8542\n",
            "Epoch 519/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8746 - val_loss: 0.3722 - val_accuracy: 0.8531\n",
            "Epoch 520/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.8752 - val_loss: 0.3722 - val_accuracy: 0.8538\n",
            "Epoch 521/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8759 - val_loss: 0.3722 - val_accuracy: 0.8538\n",
            "Epoch 522/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8757 - val_loss: 0.3721 - val_accuracy: 0.8531\n",
            "Epoch 523/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3015 - accuracy: 0.8767 - val_loss: 0.3720 - val_accuracy: 0.8531\n",
            "Epoch 524/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8755 - val_loss: 0.3720 - val_accuracy: 0.8519\n",
            "Epoch 525/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8759 - val_loss: 0.3718 - val_accuracy: 0.8519\n",
            "Epoch 526/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8759 - val_loss: 0.3717 - val_accuracy: 0.8535\n",
            "Epoch 527/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8748 - val_loss: 0.3722 - val_accuracy: 0.8523\n",
            "Epoch 528/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.3722 - val_accuracy: 0.8527\n",
            "Epoch 529/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8770 - val_loss: 0.3723 - val_accuracy: 0.8531\n",
            "Epoch 530/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8763 - val_loss: 0.3721 - val_accuracy: 0.8527\n",
            "Epoch 531/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8763 - val_loss: 0.3723 - val_accuracy: 0.8527\n",
            "Epoch 532/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8755 - val_loss: 0.3720 - val_accuracy: 0.8527\n",
            "Epoch 533/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8755 - val_loss: 0.3717 - val_accuracy: 0.8535\n",
            "Epoch 534/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8755 - val_loss: 0.3719 - val_accuracy: 0.8538\n",
            "Epoch 535/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3015 - accuracy: 0.8750 - val_loss: 0.3719 - val_accuracy: 0.8519\n",
            "Epoch 536/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8752 - val_loss: 0.3721 - val_accuracy: 0.8523\n",
            "Epoch 537/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8753 - val_loss: 0.3721 - val_accuracy: 0.8531\n",
            "Epoch 538/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.8755 - val_loss: 0.3723 - val_accuracy: 0.8519\n",
            "Epoch 539/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3017 - accuracy: 0.8748 - val_loss: 0.3720 - val_accuracy: 0.8512\n",
            "Epoch 540/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3014 - accuracy: 0.8753 - val_loss: 0.3722 - val_accuracy: 0.8516\n",
            "Epoch 541/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8757 - val_loss: 0.3721 - val_accuracy: 0.8508\n",
            "Epoch 542/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8753 - val_loss: 0.3718 - val_accuracy: 0.8512\n",
            "Epoch 543/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8755 - val_loss: 0.3719 - val_accuracy: 0.8516\n",
            "Epoch 544/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8763 - val_loss: 0.3721 - val_accuracy: 0.8501\n",
            "Epoch 545/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8763 - val_loss: 0.3720 - val_accuracy: 0.8504\n",
            "Epoch 546/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8763 - val_loss: 0.3719 - val_accuracy: 0.8508\n",
            "Epoch 547/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8761 - val_loss: 0.3715 - val_accuracy: 0.8527\n",
            "Epoch 548/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8757 - val_loss: 0.3713 - val_accuracy: 0.8527\n",
            "Epoch 549/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8761 - val_loss: 0.3714 - val_accuracy: 0.8519\n",
            "Epoch 550/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8759 - val_loss: 0.3719 - val_accuracy: 0.8519\n",
            "Epoch 551/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8757 - val_loss: 0.3721 - val_accuracy: 0.8519\n",
            "Epoch 552/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3015 - accuracy: 0.8767 - val_loss: 0.3718 - val_accuracy: 0.8535\n",
            "Epoch 553/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8757 - val_loss: 0.3718 - val_accuracy: 0.8527\n",
            "Epoch 554/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8761 - val_loss: 0.3720 - val_accuracy: 0.8519\n",
            "Epoch 555/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8763 - val_loss: 0.3720 - val_accuracy: 0.8523\n",
            "Epoch 556/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8768 - val_loss: 0.3720 - val_accuracy: 0.8527\n",
            "Epoch 557/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8767 - val_loss: 0.3721 - val_accuracy: 0.8527\n",
            "Epoch 558/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8757 - val_loss: 0.3721 - val_accuracy: 0.8527\n",
            "Epoch 559/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8759 - val_loss: 0.3722 - val_accuracy: 0.8523\n",
            "Epoch 560/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8755 - val_loss: 0.3721 - val_accuracy: 0.8523\n",
            "Epoch 561/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8755 - val_loss: 0.3720 - val_accuracy: 0.8523\n",
            "Epoch 562/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3014 - accuracy: 0.8753 - val_loss: 0.3719 - val_accuracy: 0.8516\n",
            "Epoch 563/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8753 - val_loss: 0.3719 - val_accuracy: 0.8519\n",
            "Epoch 564/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8761 - val_loss: 0.3721 - val_accuracy: 0.8519\n",
            "Epoch 565/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8759 - val_loss: 0.3723 - val_accuracy: 0.8508\n",
            "Epoch 566/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3014 - accuracy: 0.8759 - val_loss: 0.3726 - val_accuracy: 0.8512\n",
            "Epoch 567/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3017 - accuracy: 0.8774 - val_loss: 0.3728 - val_accuracy: 0.8527\n",
            "Epoch 568/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8755 - val_loss: 0.3728 - val_accuracy: 0.8516\n",
            "Epoch 569/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8757 - val_loss: 0.3727 - val_accuracy: 0.8519\n",
            "Epoch 570/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8744 - val_loss: 0.3721 - val_accuracy: 0.8523\n",
            "Epoch 571/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8755 - val_loss: 0.3719 - val_accuracy: 0.8516\n",
            "Epoch 572/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8753 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 573/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8755 - val_loss: 0.3716 - val_accuracy: 0.8523\n",
            "Epoch 574/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8753 - val_loss: 0.3718 - val_accuracy: 0.8523\n",
            "Epoch 575/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8757 - val_loss: 0.3720 - val_accuracy: 0.8531\n",
            "Epoch 576/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8750 - val_loss: 0.3720 - val_accuracy: 0.8527\n",
            "Epoch 577/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.8753 - val_loss: 0.3721 - val_accuracy: 0.8523\n",
            "Epoch 578/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3015 - accuracy: 0.8753 - val_loss: 0.3722 - val_accuracy: 0.8519\n",
            "Epoch 579/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8757 - val_loss: 0.3723 - val_accuracy: 0.8523\n",
            "Epoch 580/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8759 - val_loss: 0.3723 - val_accuracy: 0.8523\n",
            "Epoch 581/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8761 - val_loss: 0.3723 - val_accuracy: 0.8519\n",
            "Epoch 582/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8763 - val_loss: 0.3723 - val_accuracy: 0.8527\n",
            "Epoch 583/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8757 - val_loss: 0.3721 - val_accuracy: 0.8516\n",
            "Epoch 584/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8757 - val_loss: 0.3719 - val_accuracy: 0.8523\n",
            "Epoch 585/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8750 - val_loss: 0.3721 - val_accuracy: 0.8535\n",
            "Epoch 586/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8761 - val_loss: 0.3722 - val_accuracy: 0.8531\n",
            "Epoch 587/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8767 - val_loss: 0.3720 - val_accuracy: 0.8531\n",
            "Epoch 588/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8765 - val_loss: 0.3722 - val_accuracy: 0.8523\n",
            "Epoch 589/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8761 - val_loss: 0.3722 - val_accuracy: 0.8527\n",
            "Epoch 590/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8757 - val_loss: 0.3719 - val_accuracy: 0.8516\n",
            "Epoch 591/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3014 - accuracy: 0.8757 - val_loss: 0.3717 - val_accuracy: 0.8527\n",
            "Epoch 592/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8752 - val_loss: 0.3717 - val_accuracy: 0.8527\n",
            "Epoch 593/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8761 - val_loss: 0.3717 - val_accuracy: 0.8523\n",
            "Epoch 594/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3015 - accuracy: 0.8757 - val_loss: 0.3720 - val_accuracy: 0.8523\n",
            "Epoch 595/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3019 - accuracy: 0.8752 - val_loss: 0.3725 - val_accuracy: 0.8523\n",
            "Epoch 596/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8770 - val_loss: 0.3722 - val_accuracy: 0.8512\n",
            "Epoch 597/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 0.8768 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 598/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8757 - val_loss: 0.3726 - val_accuracy: 0.8519\n",
            "Epoch 599/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3013 - accuracy: 0.8763 - val_loss: 0.3725 - val_accuracy: 0.8516\n",
            "Epoch 600/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8755 - val_loss: 0.3722 - val_accuracy: 0.8512\n",
            "Epoch 601/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8759 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
            "Epoch 602/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8752 - val_loss: 0.3715 - val_accuracy: 0.8531\n",
            "Epoch 603/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8752 - val_loss: 0.3714 - val_accuracy: 0.8516\n",
            "Epoch 604/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8763 - val_loss: 0.3717 - val_accuracy: 0.8523\n",
            "Epoch 605/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8757 - val_loss: 0.3721 - val_accuracy: 0.8523\n",
            "Epoch 606/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3014 - accuracy: 0.8763 - val_loss: 0.3720 - val_accuracy: 0.8527\n",
            "Epoch 607/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3013 - accuracy: 0.8768 - val_loss: 0.3721 - val_accuracy: 0.8519\n",
            "Epoch 608/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8757 - val_loss: 0.3719 - val_accuracy: 0.8523\n",
            "Epoch 609/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8750 - val_loss: 0.3718 - val_accuracy: 0.8512\n",
            "Epoch 610/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3012 - accuracy: 0.8765 - val_loss: 0.3720 - val_accuracy: 0.8527\n",
            "Epoch 611/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8759 - val_loss: 0.3722 - val_accuracy: 0.8531\n",
            "Epoch 612/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8768 - val_loss: 0.3724 - val_accuracy: 0.8523\n",
            "Epoch 613/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8770 - val_loss: 0.3724 - val_accuracy: 0.8531\n",
            "Epoch 614/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8757 - val_loss: 0.3726 - val_accuracy: 0.8538\n",
            "Epoch 615/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8757 - val_loss: 0.3727 - val_accuracy: 0.8538\n",
            "Epoch 616/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3016 - accuracy: 0.8767 - val_loss: 0.3727 - val_accuracy: 0.8516\n",
            "Epoch 617/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8763 - val_loss: 0.3726 - val_accuracy: 0.8535\n",
            "Epoch 618/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8759 - val_loss: 0.3723 - val_accuracy: 0.8516\n",
            "Epoch 619/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3014 - accuracy: 0.8753 - val_loss: 0.3722 - val_accuracy: 0.8512\n",
            "Epoch 620/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8755 - val_loss: 0.3720 - val_accuracy: 0.8523\n",
            "Epoch 621/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8759 - val_loss: 0.3719 - val_accuracy: 0.8538\n",
            "Epoch 622/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8770 - val_loss: 0.3718 - val_accuracy: 0.8523\n",
            "Epoch 623/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8770 - val_loss: 0.3721 - val_accuracy: 0.8519\n",
            "Epoch 624/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8768 - val_loss: 0.3723 - val_accuracy: 0.8531\n",
            "Epoch 625/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8761 - val_loss: 0.3725 - val_accuracy: 0.8512\n",
            "Epoch 626/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3012 - accuracy: 0.8770 - val_loss: 0.3727 - val_accuracy: 0.8519\n",
            "Epoch 627/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8770 - val_loss: 0.3729 - val_accuracy: 0.8519\n",
            "Epoch 628/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8768 - val_loss: 0.3726 - val_accuracy: 0.8512\n",
            "Epoch 629/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8763 - val_loss: 0.3725 - val_accuracy: 0.8516\n",
            "Epoch 630/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8761 - val_loss: 0.3725 - val_accuracy: 0.8527\n",
            "Epoch 631/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8753 - val_loss: 0.3727 - val_accuracy: 0.8523\n",
            "Epoch 632/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8759 - val_loss: 0.3725 - val_accuracy: 0.8523\n",
            "Epoch 633/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8763 - val_loss: 0.3724 - val_accuracy: 0.8519\n",
            "Epoch 634/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8757 - val_loss: 0.3725 - val_accuracy: 0.8531\n",
            "Epoch 635/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8759 - val_loss: 0.3723 - val_accuracy: 0.8519\n",
            "Epoch 636/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3013 - accuracy: 0.8768 - val_loss: 0.3722 - val_accuracy: 0.8512\n",
            "Epoch 637/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8772 - val_loss: 0.3722 - val_accuracy: 0.8512\n",
            "Epoch 638/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3012 - accuracy: 0.8767 - val_loss: 0.3721 - val_accuracy: 0.8535\n",
            "Epoch 639/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8755 - val_loss: 0.3725 - val_accuracy: 0.8538\n",
            "Epoch 640/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3012 - accuracy: 0.8757 - val_loss: 0.3727 - val_accuracy: 0.8531\n",
            "Epoch 641/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3013 - accuracy: 0.8780 - val_loss: 0.3729 - val_accuracy: 0.8523\n",
            "Epoch 642/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3012 - accuracy: 0.8774 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 643/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8750 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 644/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8755 - val_loss: 0.3724 - val_accuracy: 0.8531\n",
            "Epoch 645/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3011 - accuracy: 0.8767 - val_loss: 0.3725 - val_accuracy: 0.8531\n",
            "Epoch 646/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8768 - val_loss: 0.3725 - val_accuracy: 0.8519\n",
            "Epoch 647/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3013 - accuracy: 0.8765 - val_loss: 0.3725 - val_accuracy: 0.8527\n",
            "Epoch 648/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8772 - val_loss: 0.3725 - val_accuracy: 0.8523\n",
            "Epoch 649/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8763 - val_loss: 0.3726 - val_accuracy: 0.8523\n",
            "Epoch 650/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3013 - accuracy: 0.8757 - val_loss: 0.3727 - val_accuracy: 0.8538\n",
            "Epoch 651/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8753 - val_loss: 0.3725 - val_accuracy: 0.8535\n",
            "Epoch 652/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3011 - accuracy: 0.8772 - val_loss: 0.3725 - val_accuracy: 0.8512\n",
            "Epoch 653/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8770 - val_loss: 0.3722 - val_accuracy: 0.8508\n",
            "Epoch 654/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3012 - accuracy: 0.8768 - val_loss: 0.3722 - val_accuracy: 0.8519\n",
            "Epoch 655/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8768 - val_loss: 0.3726 - val_accuracy: 0.8516\n",
            "Epoch 656/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8770 - val_loss: 0.3727 - val_accuracy: 0.8523\n",
            "Epoch 657/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3011 - accuracy: 0.8772 - val_loss: 0.3726 - val_accuracy: 0.8531\n",
            "Epoch 658/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8768 - val_loss: 0.3727 - val_accuracy: 0.8527\n",
            "Epoch 659/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8774 - val_loss: 0.3726 - val_accuracy: 0.8527\n",
            "Epoch 660/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8774 - val_loss: 0.3726 - val_accuracy: 0.8523\n",
            "Epoch 661/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3014 - accuracy: 0.8761 - val_loss: 0.3729 - val_accuracy: 0.8523\n",
            "Epoch 662/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8781 - val_loss: 0.3731 - val_accuracy: 0.8508\n",
            "Epoch 663/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8774 - val_loss: 0.3731 - val_accuracy: 0.8527\n",
            "Epoch 664/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8763 - val_loss: 0.3731 - val_accuracy: 0.8527\n",
            "Epoch 665/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8757 - val_loss: 0.3727 - val_accuracy: 0.8519\n",
            "Epoch 666/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8774 - val_loss: 0.3727 - val_accuracy: 0.8527\n",
            "Epoch 667/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8772 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 668/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8765 - val_loss: 0.3726 - val_accuracy: 0.8519\n",
            "Epoch 669/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3011 - accuracy: 0.8759 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 670/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8772 - val_loss: 0.3727 - val_accuracy: 0.8527\n",
            "Epoch 671/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3011 - accuracy: 0.8768 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 672/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8765 - val_loss: 0.3727 - val_accuracy: 0.8516\n",
            "Epoch 673/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3011 - accuracy: 0.8765 - val_loss: 0.3728 - val_accuracy: 0.8519\n",
            "Epoch 674/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8772 - val_loss: 0.3729 - val_accuracy: 0.8531\n",
            "Epoch 675/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3010 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8527\n",
            "Epoch 676/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8763 - val_loss: 0.3731 - val_accuracy: 0.8519\n",
            "Epoch 677/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8761 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 678/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8770 - val_loss: 0.3730 - val_accuracy: 0.8519\n",
            "Epoch 679/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3010 - accuracy: 0.8765 - val_loss: 0.3732 - val_accuracy: 0.8516\n",
            "Epoch 680/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8763 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 681/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8763 - val_loss: 0.3732 - val_accuracy: 0.8512\n",
            "Epoch 682/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8765 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 683/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3730 - val_accuracy: 0.8535\n",
            "Epoch 684/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8763 - val_loss: 0.3731 - val_accuracy: 0.8531\n",
            "Epoch 685/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8527\n",
            "Epoch 686/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8768 - val_loss: 0.3731 - val_accuracy: 0.8519\n",
            "Epoch 687/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3010 - accuracy: 0.8767 - val_loss: 0.3731 - val_accuracy: 0.8535\n",
            "Epoch 688/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3729 - val_accuracy: 0.8523\n",
            "Epoch 689/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8774 - val_loss: 0.3728 - val_accuracy: 0.8527\n",
            "Epoch 690/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8778 - val_loss: 0.3726 - val_accuracy: 0.8527\n",
            "Epoch 691/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8765 - val_loss: 0.3728 - val_accuracy: 0.8535\n",
            "Epoch 692/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8768 - val_loss: 0.3731 - val_accuracy: 0.8531\n",
            "Epoch 693/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8761 - val_loss: 0.3727 - val_accuracy: 0.8531\n",
            "Epoch 694/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3010 - accuracy: 0.8772 - val_loss: 0.3726 - val_accuracy: 0.8519\n",
            "Epoch 695/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3728 - val_accuracy: 0.8531\n",
            "Epoch 696/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8767 - val_loss: 0.3727 - val_accuracy: 0.8535\n",
            "Epoch 697/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8763 - val_loss: 0.3728 - val_accuracy: 0.8527\n",
            "Epoch 698/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8759 - val_loss: 0.3730 - val_accuracy: 0.8516\n",
            "Epoch 699/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3730 - val_accuracy: 0.8516\n",
            "Epoch 700/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3009 - accuracy: 0.8763 - val_loss: 0.3731 - val_accuracy: 0.8531\n",
            "Epoch 701/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3731 - val_accuracy: 0.8527\n",
            "Epoch 702/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8765 - val_loss: 0.3734 - val_accuracy: 0.8538\n",
            "Epoch 703/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8767 - val_loss: 0.3737 - val_accuracy: 0.8523\n",
            "Epoch 704/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8761 - val_loss: 0.3735 - val_accuracy: 0.8538\n",
            "Epoch 705/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8761 - val_loss: 0.3730 - val_accuracy: 0.8519\n",
            "Epoch 706/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8767 - val_loss: 0.3730 - val_accuracy: 0.8516\n",
            "Epoch 707/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8770 - val_loss: 0.3728 - val_accuracy: 0.8516\n",
            "Epoch 708/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8770 - val_loss: 0.3733 - val_accuracy: 0.8504\n",
            "Epoch 709/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3012 - accuracy: 0.8761 - val_loss: 0.3737 - val_accuracy: 0.8512\n",
            "Epoch 710/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8765 - val_loss: 0.3734 - val_accuracy: 0.8504\n",
            "Epoch 711/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3731 - val_accuracy: 0.8542\n",
            "Epoch 712/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8755 - val_loss: 0.3734 - val_accuracy: 0.8542\n",
            "Epoch 713/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3013 - accuracy: 0.8757 - val_loss: 0.3730 - val_accuracy: 0.8527\n",
            "Epoch 714/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3011 - accuracy: 0.8770 - val_loss: 0.3733 - val_accuracy: 0.8516\n",
            "Epoch 715/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8759 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 716/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8767 - val_loss: 0.3731 - val_accuracy: 0.8516\n",
            "Epoch 717/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8770 - val_loss: 0.3730 - val_accuracy: 0.8516\n",
            "Epoch 718/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8765 - val_loss: 0.3731 - val_accuracy: 0.8512\n",
            "Epoch 719/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 720/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 721/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3009 - accuracy: 0.8770 - val_loss: 0.3734 - val_accuracy: 0.8523\n",
            "Epoch 722/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3011 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 723/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8535\n",
            "Epoch 724/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8765 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 725/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 726/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8755 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 727/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8774 - val_loss: 0.3729 - val_accuracy: 0.8523\n",
            "Epoch 728/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8776 - val_loss: 0.3731 - val_accuracy: 0.8512\n",
            "Epoch 729/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.8755 - val_loss: 0.3740 - val_accuracy: 0.8527\n",
            "Epoch 730/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8763 - val_loss: 0.3735 - val_accuracy: 0.8501\n",
            "Epoch 731/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8763 - val_loss: 0.3736 - val_accuracy: 0.8504\n",
            "Epoch 732/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8497\n",
            "Epoch 733/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8759 - val_loss: 0.3733 - val_accuracy: 0.8531\n",
            "Epoch 734/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8759 - val_loss: 0.3734 - val_accuracy: 0.8516\n",
            "Epoch 735/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8765 - val_loss: 0.3734 - val_accuracy: 0.8508\n",
            "Epoch 736/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8772 - val_loss: 0.3732 - val_accuracy: 0.8512\n",
            "Epoch 737/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8776 - val_loss: 0.3733 - val_accuracy: 0.8512\n",
            "Epoch 738/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8776 - val_loss: 0.3731 - val_accuracy: 0.8508\n",
            "Epoch 739/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3010 - accuracy: 0.8774 - val_loss: 0.3731 - val_accuracy: 0.8516\n",
            "Epoch 740/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3009 - accuracy: 0.8774 - val_loss: 0.3733 - val_accuracy: 0.8512\n",
            "Epoch 741/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3009 - accuracy: 0.8757 - val_loss: 0.3734 - val_accuracy: 0.8508\n",
            "Epoch 742/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8755 - val_loss: 0.3736 - val_accuracy: 0.8523\n",
            "Epoch 743/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8770 - val_loss: 0.3736 - val_accuracy: 0.8519\n",
            "Epoch 744/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8765 - val_loss: 0.3735 - val_accuracy: 0.8508\n",
            "Epoch 745/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3009 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8531\n",
            "Epoch 746/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8776 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 747/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 748/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8781 - val_loss: 0.3731 - val_accuracy: 0.8527\n",
            "Epoch 749/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8776 - val_loss: 0.3730 - val_accuracy: 0.8527\n",
            "Epoch 750/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 0.8765 - val_loss: 0.3729 - val_accuracy: 0.8535\n",
            "Epoch 751/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8778 - val_loss: 0.3729 - val_accuracy: 0.8542\n",
            "Epoch 752/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8776 - val_loss: 0.3730 - val_accuracy: 0.8531\n",
            "Epoch 753/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8774 - val_loss: 0.3729 - val_accuracy: 0.8519\n",
            "Epoch 754/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3008 - accuracy: 0.8770 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 755/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8755 - val_loss: 0.3729 - val_accuracy: 0.8519\n",
            "Epoch 756/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3728 - val_accuracy: 0.8519\n",
            "Epoch 757/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8776 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 758/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8774 - val_loss: 0.3729 - val_accuracy: 0.8531\n",
            "Epoch 759/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 0.8768 - val_loss: 0.3731 - val_accuracy: 0.8538\n",
            "Epoch 760/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3007 - accuracy: 0.8781 - val_loss: 0.3732 - val_accuracy: 0.8531\n",
            "Epoch 761/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8774 - val_loss: 0.3732 - val_accuracy: 0.8516\n",
            "Epoch 762/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8778 - val_loss: 0.3731 - val_accuracy: 0.8516\n",
            "Epoch 763/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8776 - val_loss: 0.3730 - val_accuracy: 0.8516\n",
            "Epoch 764/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8770 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 765/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8767 - val_loss: 0.3734 - val_accuracy: 0.8527\n",
            "Epoch 766/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8772 - val_loss: 0.3732 - val_accuracy: 0.8523\n",
            "Epoch 767/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3009 - accuracy: 0.8759 - val_loss: 0.3732 - val_accuracy: 0.8535\n",
            "Epoch 768/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8765 - val_loss: 0.3732 - val_accuracy: 0.8542\n",
            "Epoch 769/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3007 - accuracy: 0.8768 - val_loss: 0.3732 - val_accuracy: 0.8516\n",
            "Epoch 770/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3008 - accuracy: 0.8776 - val_loss: 0.3735 - val_accuracy: 0.8508\n",
            "Epoch 771/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8763 - val_loss: 0.3733 - val_accuracy: 0.8508\n",
            "Epoch 772/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8757 - val_loss: 0.3732 - val_accuracy: 0.8504\n",
            "Epoch 773/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3008 - accuracy: 0.8759 - val_loss: 0.3729 - val_accuracy: 0.8523\n",
            "Epoch 774/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3008 - accuracy: 0.8761 - val_loss: 0.3727 - val_accuracy: 0.8527\n",
            "Epoch 775/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3729 - val_accuracy: 0.8519\n",
            "Epoch 776/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8770 - val_loss: 0.3733 - val_accuracy: 0.8535\n",
            "Epoch 777/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8770 - val_loss: 0.3736 - val_accuracy: 0.8535\n",
            "Epoch 778/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 0.8780 - val_loss: 0.3734 - val_accuracy: 0.8535\n",
            "Epoch 779/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3007 - accuracy: 0.8774 - val_loss: 0.3731 - val_accuracy: 0.8527\n",
            "Epoch 780/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3007 - accuracy: 0.8774 - val_loss: 0.3729 - val_accuracy: 0.8527\n",
            "Epoch 781/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3007 - accuracy: 0.8770 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 782/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 783/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8772 - val_loss: 0.3730 - val_accuracy: 0.8531\n",
            "Epoch 784/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 785/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8768 - val_loss: 0.3734 - val_accuracy: 0.8519\n",
            "Epoch 786/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 0.8772 - val_loss: 0.3733 - val_accuracy: 0.8508\n",
            "Epoch 787/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3731 - val_accuracy: 0.8527\n",
            "Epoch 788/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3007 - accuracy: 0.8761 - val_loss: 0.3730 - val_accuracy: 0.8538\n",
            "Epoch 789/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8774 - val_loss: 0.3730 - val_accuracy: 0.8527\n",
            "Epoch 790/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8776 - val_loss: 0.3729 - val_accuracy: 0.8516\n",
            "Epoch 791/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 0.8778 - val_loss: 0.3732 - val_accuracy: 0.8523\n",
            "Epoch 792/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8774 - val_loss: 0.3732 - val_accuracy: 0.8516\n",
            "Epoch 793/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3009 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 794/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8765 - val_loss: 0.3732 - val_accuracy: 0.8523\n",
            "Epoch 795/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8776 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 796/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8527\n",
            "Epoch 797/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3007 - accuracy: 0.8770 - val_loss: 0.3731 - val_accuracy: 0.8531\n",
            "Epoch 798/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8780 - val_loss: 0.3729 - val_accuracy: 0.8527\n",
            "Epoch 799/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3007 - accuracy: 0.8780 - val_loss: 0.3730 - val_accuracy: 0.8531\n",
            "Epoch 800/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3006 - accuracy: 0.8770 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 801/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8780 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 802/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3007 - accuracy: 0.8776 - val_loss: 0.3732 - val_accuracy: 0.8531\n",
            "Epoch 803/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8768 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 804/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3006 - accuracy: 0.8767 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 805/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3734 - val_accuracy: 0.8531\n",
            "Epoch 806/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3736 - val_accuracy: 0.8523\n",
            "Epoch 807/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3735 - val_accuracy: 0.8523\n",
            "Epoch 808/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8780 - val_loss: 0.3733 - val_accuracy: 0.8538\n",
            "Epoch 809/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8776 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 810/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8772 - val_loss: 0.3734 - val_accuracy: 0.8535\n",
            "Epoch 811/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8780 - val_loss: 0.3735 - val_accuracy: 0.8531\n",
            "Epoch 812/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3735 - val_accuracy: 0.8527\n",
            "Epoch 813/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8768 - val_loss: 0.3735 - val_accuracy: 0.8531\n",
            "Epoch 814/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3006 - accuracy: 0.8776 - val_loss: 0.3736 - val_accuracy: 0.8527\n",
            "Epoch 815/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8772 - val_loss: 0.3736 - val_accuracy: 0.8527\n",
            "Epoch 816/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8774 - val_loss: 0.3736 - val_accuracy: 0.8531\n",
            "Epoch 817/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3005 - accuracy: 0.8770 - val_loss: 0.3737 - val_accuracy: 0.8531\n",
            "Epoch 818/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3008 - accuracy: 0.8761 - val_loss: 0.3740 - val_accuracy: 0.8542\n",
            "Epoch 819/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3007 - accuracy: 0.8770 - val_loss: 0.3737 - val_accuracy: 0.8531\n",
            "Epoch 820/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8776 - val_loss: 0.3737 - val_accuracy: 0.8531\n",
            "Epoch 821/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8780 - val_loss: 0.3736 - val_accuracy: 0.8523\n",
            "Epoch 822/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8767 - val_loss: 0.3738 - val_accuracy: 0.8516\n",
            "Epoch 823/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3735 - val_accuracy: 0.8523\n",
            "Epoch 824/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8767 - val_loss: 0.3737 - val_accuracy: 0.8527\n",
            "Epoch 825/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3734 - val_accuracy: 0.8519\n",
            "Epoch 826/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 827/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3006 - accuracy: 0.8780 - val_loss: 0.3734 - val_accuracy: 0.8527\n",
            "Epoch 828/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8781 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 829/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3732 - val_accuracy: 0.8523\n",
            "Epoch 830/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8780 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 831/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8783 - val_loss: 0.3729 - val_accuracy: 0.8538\n",
            "Epoch 832/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3732 - val_accuracy: 0.8531\n",
            "Epoch 833/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3005 - accuracy: 0.8781 - val_loss: 0.3732 - val_accuracy: 0.8527\n",
            "Epoch 834/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3007 - accuracy: 0.8774 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 835/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3735 - val_accuracy: 0.8531\n",
            "Epoch 836/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8770 - val_loss: 0.3741 - val_accuracy: 0.8527\n",
            "Epoch 837/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3008 - accuracy: 0.8772 - val_loss: 0.3735 - val_accuracy: 0.8523\n",
            "Epoch 838/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8776 - val_loss: 0.3735 - val_accuracy: 0.8527\n",
            "Epoch 839/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3005 - accuracy: 0.8781 - val_loss: 0.3734 - val_accuracy: 0.8531\n",
            "Epoch 840/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8789 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 841/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8781 - val_loss: 0.3733 - val_accuracy: 0.8531\n",
            "Epoch 842/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8772 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 843/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3733 - val_accuracy: 0.8531\n",
            "Epoch 844/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 845/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3004 - accuracy: 0.8781 - val_loss: 0.3732 - val_accuracy: 0.8527\n",
            "Epoch 846/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3007 - accuracy: 0.8778 - val_loss: 0.3735 - val_accuracy: 0.8523\n",
            "Epoch 847/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3005 - accuracy: 0.8780 - val_loss: 0.3736 - val_accuracy: 0.8516\n",
            "Epoch 848/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3008 - accuracy: 0.8772 - val_loss: 0.3735 - val_accuracy: 0.8535\n",
            "Epoch 849/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3735 - val_accuracy: 0.8527\n",
            "Epoch 850/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3737 - val_accuracy: 0.8516\n",
            "Epoch 851/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3737 - val_accuracy: 0.8516\n",
            "Epoch 852/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3736 - val_accuracy: 0.8516\n",
            "Epoch 853/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3006 - accuracy: 0.8789 - val_loss: 0.3736 - val_accuracy: 0.8519\n",
            "Epoch 854/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3738 - val_accuracy: 0.8523\n",
            "Epoch 855/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3005 - accuracy: 0.8774 - val_loss: 0.3738 - val_accuracy: 0.8519\n",
            "Epoch 856/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8781 - val_loss: 0.3738 - val_accuracy: 0.8523\n",
            "Epoch 857/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3736 - val_accuracy: 0.8523\n",
            "Epoch 858/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8757 - val_loss: 0.3739 - val_accuracy: 0.8531\n",
            "Epoch 859/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3008 - accuracy: 0.8763 - val_loss: 0.3734 - val_accuracy: 0.8527\n",
            "Epoch 860/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3004 - accuracy: 0.8763 - val_loss: 0.3734 - val_accuracy: 0.8527\n",
            "Epoch 861/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3006 - accuracy: 0.8765 - val_loss: 0.3734 - val_accuracy: 0.8546\n",
            "Epoch 862/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8770 - val_loss: 0.3733 - val_accuracy: 0.8531\n",
            "Epoch 863/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 864/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3006 - accuracy: 0.8785 - val_loss: 0.3736 - val_accuracy: 0.8516\n",
            "Epoch 865/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8780 - val_loss: 0.3736 - val_accuracy: 0.8516\n",
            "Epoch 866/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8767 - val_loss: 0.3734 - val_accuracy: 0.8523\n",
            "Epoch 867/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8774 - val_loss: 0.3729 - val_accuracy: 0.8531\n",
            "Epoch 868/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3005 - accuracy: 0.8780 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 869/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3010 - accuracy: 0.8770 - val_loss: 0.3732 - val_accuracy: 0.8527\n",
            "Epoch 870/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3006 - accuracy: 0.8785 - val_loss: 0.3730 - val_accuracy: 0.8519\n",
            "Epoch 871/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8783 - val_loss: 0.3731 - val_accuracy: 0.8519\n",
            "Epoch 872/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8776 - val_loss: 0.3733 - val_accuracy: 0.8508\n",
            "Epoch 873/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3004 - accuracy: 0.8768 - val_loss: 0.3730 - val_accuracy: 0.8512\n",
            "Epoch 874/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8781 - val_loss: 0.3730 - val_accuracy: 0.8512\n",
            "Epoch 875/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3005 - accuracy: 0.8783 - val_loss: 0.3734 - val_accuracy: 0.8516\n",
            "Epoch 876/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8772 - val_loss: 0.3736 - val_accuracy: 0.8527\n",
            "Epoch 877/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8772 - val_loss: 0.3739 - val_accuracy: 0.8535\n",
            "Epoch 878/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8768 - val_loss: 0.3738 - val_accuracy: 0.8527\n",
            "Epoch 879/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8768 - val_loss: 0.3736 - val_accuracy: 0.8523\n",
            "Epoch 880/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8772 - val_loss: 0.3734 - val_accuracy: 0.8516\n",
            "Epoch 881/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8772 - val_loss: 0.3734 - val_accuracy: 0.8519\n",
            "Epoch 882/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3006 - accuracy: 0.8778 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 883/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3008 - accuracy: 0.8765 - val_loss: 0.3733 - val_accuracy: 0.8542\n",
            "Epoch 884/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8763 - val_loss: 0.3728 - val_accuracy: 0.8538\n",
            "Epoch 885/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8772 - val_loss: 0.3729 - val_accuracy: 0.8527\n",
            "Epoch 886/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8778 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 887/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3738 - val_accuracy: 0.8519\n",
            "Epoch 888/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8768 - val_loss: 0.3736 - val_accuracy: 0.8512\n",
            "Epoch 889/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8770 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 890/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8780 - val_loss: 0.3730 - val_accuracy: 0.8527\n",
            "Epoch 891/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8781 - val_loss: 0.3732 - val_accuracy: 0.8523\n",
            "Epoch 892/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8776 - val_loss: 0.3736 - val_accuracy: 0.8535\n",
            "Epoch 893/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3736 - val_accuracy: 0.8519\n",
            "Epoch 894/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8785 - val_loss: 0.3734 - val_accuracy: 0.8527\n",
            "Epoch 895/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3009 - accuracy: 0.8778 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 896/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3730 - val_accuracy: 0.8535\n",
            "Epoch 897/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3730 - val_accuracy: 0.8535\n",
            "Epoch 898/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3005 - accuracy: 0.8767 - val_loss: 0.3726 - val_accuracy: 0.8531\n",
            "Epoch 899/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3729 - val_accuracy: 0.8516\n",
            "Epoch 900/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3005 - accuracy: 0.8774 - val_loss: 0.3730 - val_accuracy: 0.8531\n",
            "Epoch 901/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8774 - val_loss: 0.3729 - val_accuracy: 0.8535\n",
            "Epoch 902/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3730 - val_accuracy: 0.8519\n",
            "Epoch 903/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3729 - val_accuracy: 0.8512\n",
            "Epoch 904/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8765 - val_loss: 0.3728 - val_accuracy: 0.8519\n",
            "Epoch 905/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3727 - val_accuracy: 0.8527\n",
            "Epoch 906/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3729 - val_accuracy: 0.8523\n",
            "Epoch 907/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8778 - val_loss: 0.3729 - val_accuracy: 0.8512\n",
            "Epoch 908/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3005 - accuracy: 0.8780 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 909/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3006 - accuracy: 0.8776 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 910/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8768 - val_loss: 0.3735 - val_accuracy: 0.8523\n",
            "Epoch 911/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8781 - val_loss: 0.3737 - val_accuracy: 0.8527\n",
            "Epoch 912/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8781 - val_loss: 0.3736 - val_accuracy: 0.8519\n",
            "Epoch 913/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8774 - val_loss: 0.3736 - val_accuracy: 0.8519\n",
            "Epoch 914/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8770 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 915/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3735 - val_accuracy: 0.8512\n",
            "Epoch 916/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8770 - val_loss: 0.3734 - val_accuracy: 0.8508\n",
            "Epoch 917/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8772 - val_loss: 0.3735 - val_accuracy: 0.8504\n",
            "Epoch 918/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8768 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 919/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8774 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 920/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8778 - val_loss: 0.3734 - val_accuracy: 0.8535\n",
            "Epoch 921/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8776 - val_loss: 0.3733 - val_accuracy: 0.8538\n",
            "Epoch 922/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8780 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 923/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3003 - accuracy: 0.8780 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 924/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3728 - val_accuracy: 0.8519\n",
            "Epoch 925/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8772 - val_loss: 0.3728 - val_accuracy: 0.8535\n",
            "Epoch 926/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8772 - val_loss: 0.3728 - val_accuracy: 0.8535\n",
            "Epoch 927/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8774 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 928/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3004 - accuracy: 0.8767 - val_loss: 0.3731 - val_accuracy: 0.8516\n",
            "Epoch 929/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8767 - val_loss: 0.3734 - val_accuracy: 0.8516\n",
            "Epoch 930/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8765 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 931/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3005 - accuracy: 0.8768 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 932/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3732 - val_accuracy: 0.8535\n",
            "Epoch 933/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3732 - val_accuracy: 0.8523\n",
            "Epoch 934/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3733 - val_accuracy: 0.8516\n",
            "Epoch 935/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8778 - val_loss: 0.3731 - val_accuracy: 0.8512\n",
            "Epoch 936/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8776 - val_loss: 0.3730 - val_accuracy: 0.8519\n",
            "Epoch 937/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8774 - val_loss: 0.3727 - val_accuracy: 0.8516\n",
            "Epoch 938/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8774 - val_loss: 0.3726 - val_accuracy: 0.8527\n",
            "Epoch 939/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8768 - val_loss: 0.3727 - val_accuracy: 0.8523\n",
            "Epoch 940/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8768 - val_loss: 0.3730 - val_accuracy: 0.8519\n",
            "Epoch 941/1000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3729 - val_accuracy: 0.8523\n",
            "Epoch 942/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 943/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3002 - accuracy: 0.8774 - val_loss: 0.3732 - val_accuracy: 0.8516\n",
            "Epoch 944/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8774 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 945/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8768 - val_loss: 0.3730 - val_accuracy: 0.8516\n",
            "Epoch 946/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3003 - accuracy: 0.8772 - val_loss: 0.3728 - val_accuracy: 0.8519\n",
            "Epoch 947/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8776 - val_loss: 0.3729 - val_accuracy: 0.8519\n",
            "Epoch 948/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3007 - accuracy: 0.8765 - val_loss: 0.3729 - val_accuracy: 0.8512\n",
            "Epoch 949/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3004 - accuracy: 0.8783 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 950/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8780 - val_loss: 0.3730 - val_accuracy: 0.8538\n",
            "Epoch 951/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8770 - val_loss: 0.3731 - val_accuracy: 0.8519\n",
            "Epoch 952/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3004 - accuracy: 0.8781 - val_loss: 0.3730 - val_accuracy: 0.8527\n",
            "Epoch 953/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8778 - val_loss: 0.3730 - val_accuracy: 0.8527\n",
            "Epoch 954/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8765 - val_loss: 0.3731 - val_accuracy: 0.8516\n",
            "Epoch 955/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8772 - val_loss: 0.3727 - val_accuracy: 0.8531\n",
            "Epoch 956/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3004 - accuracy: 0.8780 - val_loss: 0.3731 - val_accuracy: 0.8538\n",
            "Epoch 957/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8783 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 958/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8772 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 959/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8768 - val_loss: 0.3732 - val_accuracy: 0.8527\n",
            "Epoch 960/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8774 - val_loss: 0.3732 - val_accuracy: 0.8531\n",
            "Epoch 961/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8776 - val_loss: 0.3733 - val_accuracy: 0.8523\n",
            "Epoch 962/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3004 - accuracy: 0.8768 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 963/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8778 - val_loss: 0.3731 - val_accuracy: 0.8531\n",
            "Epoch 964/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8780 - val_loss: 0.3735 - val_accuracy: 0.8535\n",
            "Epoch 965/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3733 - val_accuracy: 0.8531\n",
            "Epoch 966/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3003 - accuracy: 0.8780 - val_loss: 0.3734 - val_accuracy: 0.8519\n",
            "Epoch 967/1000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3003 - accuracy: 0.8780 - val_loss: 0.3732 - val_accuracy: 0.8531\n",
            "Epoch 968/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8776 - val_loss: 0.3731 - val_accuracy: 0.8538\n",
            "Epoch 969/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3001 - accuracy: 0.8785 - val_loss: 0.3732 - val_accuracy: 0.8516\n",
            "Epoch 970/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8767 - val_loss: 0.3733 - val_accuracy: 0.8527\n",
            "Epoch 971/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3002 - accuracy: 0.8772 - val_loss: 0.3731 - val_accuracy: 0.8523\n",
            "Epoch 972/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8778 - val_loss: 0.3730 - val_accuracy: 0.8512\n",
            "Epoch 973/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3003 - accuracy: 0.8776 - val_loss: 0.3730 - val_accuracy: 0.8527\n",
            "Epoch 974/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8774 - val_loss: 0.3728 - val_accuracy: 0.8535\n",
            "Epoch 975/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8776 - val_loss: 0.3730 - val_accuracy: 0.8535\n",
            "Epoch 976/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8763 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 977/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8770 - val_loss: 0.3730 - val_accuracy: 0.8523\n",
            "Epoch 978/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8767 - val_loss: 0.3728 - val_accuracy: 0.8527\n",
            "Epoch 979/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3002 - accuracy: 0.8774 - val_loss: 0.3727 - val_accuracy: 0.8523\n",
            "Epoch 980/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8774 - val_loss: 0.3728 - val_accuracy: 0.8523\n",
            "Epoch 981/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3007 - accuracy: 0.8768 - val_loss: 0.3732 - val_accuracy: 0.8519\n",
            "Epoch 982/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3005 - accuracy: 0.8785 - val_loss: 0.3735 - val_accuracy: 0.8519\n",
            "Epoch 983/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8780 - val_loss: 0.3736 - val_accuracy: 0.8523\n",
            "Epoch 984/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8768 - val_loss: 0.3741 - val_accuracy: 0.8519\n",
            "Epoch 985/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8763 - val_loss: 0.3741 - val_accuracy: 0.8516\n",
            "Epoch 986/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3003 - accuracy: 0.8763 - val_loss: 0.3741 - val_accuracy: 0.8523\n",
            "Epoch 987/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8763 - val_loss: 0.3737 - val_accuracy: 0.8527\n",
            "Epoch 988/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3003 - accuracy: 0.8767 - val_loss: 0.3736 - val_accuracy: 0.8531\n",
            "Epoch 989/1000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3001 - accuracy: 0.8768 - val_loss: 0.3734 - val_accuracy: 0.8535\n",
            "Epoch 990/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8780 - val_loss: 0.3734 - val_accuracy: 0.8523\n",
            "Epoch 991/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3001 - accuracy: 0.8774 - val_loss: 0.3737 - val_accuracy: 0.8523\n",
            "Epoch 992/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8768 - val_loss: 0.3735 - val_accuracy: 0.8527\n",
            "Epoch 993/1000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3003 - accuracy: 0.8772 - val_loss: 0.3734 - val_accuracy: 0.8527\n",
            "Epoch 994/1000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3004 - accuracy: 0.8767 - val_loss: 0.3733 - val_accuracy: 0.8519\n",
            "Epoch 995/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3004 - accuracy: 0.8772 - val_loss: 0.3733 - val_accuracy: 0.8531\n",
            "Epoch 996/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8774 - val_loss: 0.3735 - val_accuracy: 0.8519\n",
            "Epoch 997/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8763 - val_loss: 0.3734 - val_accuracy: 0.8523\n",
            "Epoch 998/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8774 - val_loss: 0.3737 - val_accuracy: 0.8519\n",
            "Epoch 999/1000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3003 - accuracy: 0.8772 - val_loss: 0.3737 - val_accuracy: 0.8519\n",
            "Epoch 1000/1000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.8772 - val_loss: 0.3744 - val_accuracy: 0.8512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rST9iXzEpPm",
        "outputId": "d1ac1cc0-fe7e-422c-9b37-9e9cf255029d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train','Test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "g7HSPl9EG3np",
        "outputId": "2c059c9b-695a-4f70-eb3c-c734bf4f7dff"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train','Test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WwYSiZ5_H90i",
        "outputId": "0a3b2f75-baed-4ba8-dc1d-dac70f596936"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=classifier.predict(x_test)\n",
        "ypred=(ypred >= 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kWIiwF9ITo0",
        "outputId": "fe3fbc86-93a2-411f-fe11-f0ea5c7cfd33"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test, ypred)"
      ],
      "metadata": {
        "id": "3DeIJ912Iwvg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "as1=accuracy_score(y_test, ypred)\n",
        "as1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0uoB1ZVJJoI",
        "outputId": "2aae5183-f903-4b21-e62f-a7d876949de3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.853"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the weights\n",
        "classifier.get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPk84OxWJsxi",
        "outputId": "0c22dc0c-526e-4245-cb59-3278a477ce1d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-3.59638780e-01, -9.50143412e-02, -5.47132082e-02,\n",
              "          8.91439840e-02,  1.59704108e-02, -9.20483992e-02,\n",
              "         -1.89263538e-01, -1.37758851e-01, -9.05578509e-02,\n",
              "          2.82278568e-01,  4.77267653e-02],\n",
              "        [-8.70179296e-01, -4.23904061e-01,  7.05881596e-01,\n",
              "         -7.13203430e-01,  6.12870455e-01,  4.69308347e-02,\n",
              "          1.13586307e+00,  2.39610057e-02,  2.71676838e-01,\n",
              "          2.01546818e-01,  5.14770746e-01],\n",
              "        [ 1.47968173e-01,  3.87012303e-01, -3.61351483e-02,\n",
              "         -4.41764295e-02,  1.15043493e-02,  1.06750108e-01,\n",
              "          2.48531729e-01,  2.98224300e-01, -3.21397871e-01,\n",
              "          1.17576569e-01, -2.19779965e-02],\n",
              "        [ 1.87791586e-01, -8.39901209e-01, -2.94866157e-03,\n",
              "          3.29810888e-01, -4.72582906e-01, -5.36161900e-01,\n",
              "         -1.26182199e-01, -5.00334620e-01,  2.79044449e-01,\n",
              "          7.01901317e-01,  5.33163846e-01],\n",
              "        [ 6.90631047e-02, -4.74372675e-04,  9.94331658e-01,\n",
              "          1.67554915e-01, -1.26412481e-01, -6.21187210e-01,\n",
              "          1.28212288e-01,  2.59706169e-01,  1.31989509e-01,\n",
              "          1.55563340e-01, -8.78532171e-01],\n",
              "        [ 1.24250222e-02,  9.76030231e-02,  3.87545936e-02,\n",
              "          1.26585707e-01, -2.02290311e-01, -4.83403131e-02,\n",
              "          1.96610257e-01,  1.91113763e-02,  3.84774894e-01,\n",
              "         -4.53998804e-01,  4.65243012e-02],\n",
              "        [ 3.41234088e-01,  3.66715342e-01, -2.73901552e-01,\n",
              "         -1.09233610e-01,  4.29222852e-01, -9.38490927e-02,\n",
              "          5.81918538e-01, -8.10735449e-02, -4.97201413e-01,\n",
              "         -3.46666932e-01, -2.87938505e-01],\n",
              "        [-1.95005015e-01, -3.78908247e-01,  1.10230045e-02,\n",
              "          2.33144313e-02,  1.23399958e-01,  9.69003364e-02,\n",
              "         -8.40516388e-02,  4.85562474e-01, -5.75737476e-01,\n",
              "         -1.41779885e-01,  1.07193757e-02],\n",
              "        [-9.93959531e-02, -9.62158561e-01,  6.35538936e-01,\n",
              "         -1.13761306e+00,  9.85763729e-01,  2.27287948e-01,\n",
              "         -2.66856164e-01,  7.09624231e-01,  8.49826813e-01,\n",
              "          1.05584435e-01,  2.88945474e-02],\n",
              "        [ 2.95479619e-03,  7.32569173e-02, -1.62149832e-01,\n",
              "          2.38246739e-01, -6.68875203e-02, -2.08986029e-01,\n",
              "         -2.11643472e-01, -7.60471702e-01, -7.80976176e-01,\n",
              "         -7.53821552e-01,  3.99619073e-01],\n",
              "        [ 5.60327828e-01,  2.96554625e-01, -6.90179393e-02,\n",
              "          1.70334771e-01, -2.73178220e-01,  9.12022442e-02,\n",
              "          3.62271518e-01,  7.86475763e-02, -4.20344025e-01,\n",
              "         -2.01696694e-01,  8.06151032e-02],\n",
              "        [-1.79017514e-01, -5.60519397e-01, -4.24618006e-01,\n",
              "         -1.37664899e-01, -4.65430915e-01,  1.84545875e-01,\n",
              "         -5.22045360e-04,  1.78322598e-01, -1.53870389e-01,\n",
              "         -2.37844303e-01,  3.28164637e-01],\n",
              "        [ 3.00518423e-01,  7.52972737e-02, -2.48622030e-01,\n",
              "          4.16929871e-02, -7.02303974e-03,  2.03980595e-01,\n",
              "          9.99703407e-02,  1.55699924e-01,  6.14065491e-02,\n",
              "          2.21189871e-01,  3.80978882e-01]], dtype=float32),\n",
              " array([ 0.10934229,  0.703313  , -0.0385044 , -0.3440821 ,  0.02866722,\n",
              "        -0.5657443 , -0.14692156,  0.40045232, -0.0076922 ,  0.286871  ,\n",
              "         0.14200096], dtype=float32),\n",
              " array([[-0.4268128 ,  0.48902053,  0.71354103,  0.16754639, -0.54182076,\n",
              "          0.01455277, -0.10330736],\n",
              "        [ 0.32318616, -0.31957632, -0.61489695,  0.3865669 ,  0.69943094,\n",
              "         -0.061825  ,  0.3280409 ],\n",
              "        [-0.69796884, -0.613866  ,  0.8744928 ,  1.2940038 , -0.4380508 ,\n",
              "          0.14986119,  0.94965655],\n",
              "        [-0.05186892, -0.30465785,  0.32142574,  1.1151648 , -0.14456661,\n",
              "         -0.9181018 ,  0.04716435],\n",
              "        [ 0.10576539, -0.3139064 , -0.9155272 , -0.145754  , -0.41053775,\n",
              "         -0.530087  , -0.7960466 ],\n",
              "        [ 0.55542773, -0.18239847,  0.32459462, -0.03621138, -0.6347759 ,\n",
              "          0.24767794,  0.8804536 ],\n",
              "        [-0.09918495, -0.3458904 ,  0.35494468,  0.594677  , -0.70053947,\n",
              "         -0.03749136, -0.38522264],\n",
              "        [ 0.5410856 ,  0.34300146,  0.24053946,  0.5746855 ,  0.9246437 ,\n",
              "          0.2250362 ,  0.36105734],\n",
              "        [ 0.15685979,  0.5151947 , -0.8914452 , -0.36507228,  0.62937266,\n",
              "         -0.25039592,  0.5055475 ],\n",
              "        [-0.51789486,  0.42429078, -0.00853866, -0.03785829,  0.4435817 ,\n",
              "          0.7534924 ,  0.17162593],\n",
              "        [ 0.35762733, -0.7783363 , -0.33466002,  0.60791224, -0.426944  ,\n",
              "          0.50771433,  0.17482638]], dtype=float32),\n",
              " array([ 0.18683109,  0.6991172 , -0.44654605,  0.31965694,  0.33638436,\n",
              "        -0.20213065, -0.3329924 ], dtype=float32),\n",
              " array([[ 0.90392524, -0.9967774 , -0.15720096, -0.33792242, -0.44641855],\n",
              "        [ 0.05265693,  0.47049472, -0.68138   ,  0.79826725,  0.26296163],\n",
              "        [ 1.2442851 ,  0.21558082,  0.02218034, -1.2110841 , -1.5283704 ],\n",
              "        [ 0.7506056 ,  0.65791434, -0.3233946 ,  0.5285781 ,  0.8903385 ],\n",
              "        [-0.6431645 , -1.2649446 , -0.6387107 ,  0.8824379 ,  1.323763  ],\n",
              "        [ 0.19630802, -0.33082265, -0.539011  , -0.5662586 , -0.77670217],\n",
              "        [ 1.3023477 , -1.7907445 , -0.6457114 , -0.42644066, -0.87251437]],\n",
              "       dtype=float32),\n",
              " array([ 0.48165396, -0.3200545 , -0.03840871,  0.20632179,  0.03457074],\n",
              "       dtype=float32),\n",
              " array([[ 0.74307877],\n",
              "        [-1.0560845 ],\n",
              "        [ 0.48346478],\n",
              "        [-0.9846167 ],\n",
              "        [-0.74665487]], dtype=float32),\n",
              " array([0.2724084], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}